{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1543,"status":"ok","timestamp":1733855756331,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"cQ2CgtHpipTJ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from typing import Tuple, Union, Optional, List\n","# import torchvision\n","# import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733855756331,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"MtAKMsC6HX9M"},"outputs":[],"source":["class AverageMeter():\n","    def __init__(self):\n","        self.num = 0\n","        self.tot = 0\n","\n","    def update(self, val: float, sz: float):\n","        self.num += val*sz\n","        self.tot += sz\n","\n","    def calculate(self) -> float:\n","        return self.num/self.tot"]},{"cell_type":"markdown","metadata":{"id":"4fZ6lHpejSmG"},"source":["# Base Transformer Implementation"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733855756475,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"CDGO8d3zjC9L"},"outputs":[],"source":["class AttentionHead(nn.Module):\n","  \"\"\"\n","  Adapted from 6.7920 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, dim: int, n_hidden: int, relation_aware=False):\n","      # dim: the dimension of the input\n","      # n_hidden: the dimension of the keys, queries, and values\n","\n","      super().__init__()\n","\n","      self.W_K = nn.Linear(dim, n_hidden) # W_K weight matrix\n","      self.W_Q = nn.Linear(dim, n_hidden) # W_Q weight matrix\n","      self.W_V = nn.Linear(dim, n_hidden) # W_V weight matrix\n","      self.n_hidden = n_hidden\n","\n","  def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor], relation_aware: Optional[bool], rel_K: Optional[torch.Tensor], rel_V: Optional[torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n","      # x                the inputs. shape: (B x T x dim)\n","      # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","      #                  contains 1 if (in batch b) token i should attend on token j and 0\n","      #                  otherwise. shape: (B x T x T)\n","      # rel_k and rel_V  the relative time representations, if relation_aware is False then ingore\n","      #                  shape: (B x T x T x n_hidden)\n","      #\n","      # Outputs:\n","      # attn_output      the output of performing self-attention on x. shape: (Batch x Num_tokens x n_hidden)\n","      # alpha            the attention weights (after softmax). shape: (B x T x T)\n","      #\n","\n","      out, alpha = None, None\n","      # TODO: Compute self attention on x.\n","      #       (1) First project x to the query Q, key K, value V.\n","      #       (2) Then compute the attention weights alpha as:\n","      #                  alpha = softmax(QK^T/sqrt(n_hidden))\n","      #           Make sure to take into account attn_mask such that token i does not attend on token\n","      #           j if attn_mask[b, i, j] == 0. (Hint, in such a case, what value should you set the weight\n","      #           to before the softmax so that after the softmax the value is 0?)\n","      #       (3) The output is a linear combination of the values (weighted by the alphas):\n","      #                  out = alpha V\n","      #       (4) return the output and the alpha after the softmax\n","\n","      # ======= Answer START ========\n","      Q = self.W_Q(x) # Shape: B x T x n_hidden\n","      K = self.W_K(x)\n","      V = self.W_V(x)\n","\n","      alpha = (Q @ K.transpose(1, 2)) / np.sqrt(self.n_hidden) # Shape: B x T x T\n","\n","      if relation_aware:\n","        alpha += torch.einsum('btd,btid->bti', Q, rel_K) # Shape: B x T x T\n","\n","      if attn_mask is not None:\n","        alpha[attn_mask == 0] = -float('inf')\n","\n","      # alpha = alpha.flatten(start_dim=1).softmax(dim=1).reshape(alpha.shape)\n","      alpha = alpha.softmax(dim=-1)\n","      # B x T^2 -> B x T\n","\n","      attn_output = alpha @ V # Shape: B x T x n_hidden\n","      if relation_aware:\n","        # attn_output += alpha * rel_V # Shape: B x T x n_hidden\n","        attn_output += torch.einsum('bti,btid->btd', alpha, rel_V) # Shape: B x T x n_hidden\n","      # ======= Answer  END ========\n","\n","      return attn_output#, alpha\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":151,"status":"ok","timestamp":1733855762478,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"ZjSUqhY5jFua"},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    \"\"\"\n","    Adapted from 6.7920 Fall 2024 HW3\n","    \"\"\"\n","    def __init__(self, dim: int, n_hidden: int, num_heads: int):\n","        # dim: the dimension of the input\n","        # n_hidden: the hidden dimenstion for the attention layer\n","        # num_heads: the number of attention heads\n","        super().__init__()\n","\n","        # TODO: set up your parameters for multi-head attention. You should initialize\n","        #       num_heads attention heads (see nn.ModuleList) as well as a linear layer\n","        #       that projects the concatenated outputs of each head into dim\n","        #       (what size should this linear layer be?)\n","\n","        # ======= Answer START ========\n","        self.attn_heads = nn.ModuleList([AttentionHead(dim, n_hidden) for _ in range(num_heads)])\n","        self.linear = nn.Linear(num_heads * n_hidden, dim)\n","        # ======= Answer  END ========\n","\n","    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor], relation_aware=False, rel_K=None, rel_V=None) -> Tuple[torch.Tensor, torch.Tensor]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","        #                  contains 1 if (in batch b) token i should attend on token j and 0\n","        #                  otherwise. shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      the output of performing multi-headed self-attention on x.\n","        #                  shape: (B x T x dim)\n","        # attn_alphas      the attention weights of each of the attention heads.\n","        #                  shape: (B x Num_heads x T x T)\n","\n","        attn_output, attn_alphas = None, None\n","\n","        # TODO: Compute multi-headed attention. Loop through each of your attention heads\n","        #       and collect the outputs. Concatenate them together along the hidden dimension,\n","        #       and then project them back into the output dimension (dim). Return both\n","        #       the final attention outputs as well as the alphas from each head.\n","\n","        # ======= Answer START ========\n","        B, T, _ = x.shape\n","        attn_outputs = torch.zeros((B, T, 0)).to(x.device) # device=x.device)\n","        attn_alphas = torch.zeros((B, 0, T, T)).to(x.device) # device=x.device)\n","        for head in self.attn_heads:\n","          # attn_output, attn_alpha = head(x, attn_mask, relation_aware, rel_K, rel_V)\n","          attn_output = head(x, attn_mask, relation_aware, rel_K, rel_V)\n","          attn_outputs = torch.cat((attn_outputs, attn_output), dim=-1) # concatenate the (B, T, n_hidden) tensor along last dim\n","          # attn_alphas = torch.cat((attn_alphas, attn_alpha.unsqueeze(1)), dim=1) # concat (B, 1, T, T) tensor along dimension 1\n","\n","        attn_output = self.linear(attn_outputs) # linear layer on a (B, T, n_hidden*num_heads) tensor into (B, T, n_hidden)\n","        # ======= Answer END ========\n","        return attn_output#, attn_alphas"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733855762478,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"naVlSlo1FHZf"},"outputs":[],"source":["# these are already implemented for you!\n","\n","class FFN(nn.Module):\n","    def __init__(self, dim: int, n_hidden: int):\n","        # dim       the dimension of the input\n","        # n_hidden  the width of the linear layer\n","\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, n_hidden),\n","            nn.GELU(),\n","            nn.Linear(n_hidden, dim),\n","        )\n","\n","    def forward(self, x: torch.Tensor)-> torch.Tensor:\n","        # x         the input. shape: (B x T x dim)\n","\n","        # Outputs:\n","        # out       the output of the feed-forward network: (B x T x dim)\n","        return self.net(x)\n","\n","class AttentionResidual(nn.Module):\n","    def __init__(self, dim: int, attn_dim: int, mlp_dim: int, num_heads: int):\n","        # dim       the dimension of the input\n","        # attn_dim  the hidden dimension of the attention layer\n","        # mlp_dim   the hidden layer of the FFN\n","        # num_heads the number of heads in the attention layer\n","        super().__init__()\n","        self.attn = MultiHeadedAttention(dim, attn_dim, num_heads)\n","        self.ffn = FFN(dim, mlp_dim)\n","\n","    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor, relation_aware=False, rel_K=None, rel_V=None) -> Tuple[torch.Tensor, torch.Tensor]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","        #                  contains 1 if (in batch b) token i should attend on token j and 0\n","        #                  otherwise. shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      shape: (B x T x dim)\n","        # attn_alphas      the attention weights of each of the attention heads.\n","        #                  shape: (B x Num_heads x T x T)\n","\n","        # attn_out, alphas = self.attn(x=x, attn_mask=attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","        attn_out = self.attn(x=x, attn_mask=attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","        x = attn_out + x\n","        x = self.ffn(x) + x\n","        return x#, alphas"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733855764580,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"E0Hw_fRdjIw2"},"outputs":[],"source":["class Transformer(nn.Module):\n","    \"\"\"\n","    Adapted from 6.7920 Fall 2024 HW3\n","    \"\"\"\n","    def __init__(self, dim: int, attn_dim: int, mlp_dim: int, num_heads: int, num_layers: int):\n","        # dim       the dimension of the input\n","        # attn_dim  the hidden dimension of the attention layer\n","        # mlp_dim   the hidden layer of the FFN\n","        # num_heads the number of heads in the attention layer\n","        # num_layers the number of attention layers.\n","        super().__init__()\n","\n","        # TODO: set up the parameters for the transformer!\n","        #       You should set up num_layers of AttentionResiduals\n","        #       nn.ModuleList will be helpful here.\n","\n","        # ======= Answer START ========\n","        self.layers = nn.ModuleList([AttentionResidual(dim, attn_dim, mlp_dim, num_heads) for _ in range(num_layers)])\n","        # ======= Answer END ========\n","\n","    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor, relation_aware=False, rel_K=None, rel_V=None, return_attn=False)-> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. Pass this to each of the AttentionResidual layers!\n","        #                  shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      shape: (B x T x dim)\n","        # attn_alphas      If return_attn is False, return None. Otherwise return the attention weights\n","        #                  of each of each of the attention heads for each of the layers.\n","        #                  shape: (B x Num_layers x Num_heads x T x T)\n","\n","        output, collected_attns = None, None\n","\n","        # TODO: Implement the transformer forward pass! Pass the input successively through each of the\n","        # AttentionResidual layers. If return_attn is True, collect the alphas along the way.\n","\n","        # ======= Answer START ========\n","        for layer in self.layers:\n","          # x, attn = layer(x, attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","          x = layer(x, attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","          # if return_attn:\n","          #   if collected_attns is None:\n","          #     collected_attns = attn.unsqueeze(1) # initialize as a (B, 1, num_heads, T, T) tensor\n","          #   else:\n","          #     collected_attns = torch.cat((collected_attns, attn.unsqueeze(1)), dim=1) # concatenate along first dimension\n","        output = x\n","        # ======= Answer END ========\n","\n","        return output, collected_attns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":682,"status":"error","timestamp":1733855765260,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"e13_Ce8_jNDD","outputId":"620f1c6f-2c27-411c-8569-b953e4bf5472"},"outputs":[],"source":["def perform_transformer_test_cases():\n","    num_tokens = 100\n","    batch_size = 10\n","    dim = 64\n","    num_layers = 4\n","    num_heads = 2\n","    dummy_model = Transformer(dim=dim, attn_dim=32, mlp_dim=dim, num_heads=num_heads, num_layers=num_layers).cuda()\n","\n","    inp = torch.randn(batch_size, num_tokens, dim).cuda()\n","\n","    # test case 1 regular forward pass\n","    print(\"Test Case 1\")\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=None)\n","        assert alpha is None\n","        assert output.shape == (batch_size, num_tokens, dim), f\"wrong output shape {output.shape}\"\n","\n","    # test case 2 collect attentions\n","    print(\"Test Case 2\")\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=None, return_attn=True)\n","        assert output.shape == (batch_size, num_tokens, dim), f\"wrong output shape {output.shape}\"\n","        assert alpha.shape == (batch_size, num_layers, num_heads, num_tokens, num_tokens), f\"wrong alpha shape {alpha.shape}\"\n","\n","    print(\"Test Case 3\")\n","    # test case 3 with attention mask\n","    attn_mask = torch.zeros(batch_size, num_tokens, num_tokens).cuda()\n","    attn_mask[:, torch.arange(num_tokens), torch.arange(num_tokens)] = 1\n","    attn_mask[:, torch.arange(num_tokens)[1:], torch.arange(num_tokens)[:-1]] = 1\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=attn_mask, return_attn=True)\n","        print(\"Attention mask pattern\", attn_mask[0])\n","        print(\"Alpha pattern\", alpha[0, 0, 0])\n","        assert torch.all(alpha.permute(1, 2, 0, 3, 4)[:, :, attn_mask == 0] == 0).item()\n","\n","    print(\"Test Case 4\")\n","    # test case 4 creates a causal mask where each token can only attend to previous tokens and itself\n","    causal_mask = torch.tril(torch.ones(num_tokens, num_tokens)).unsqueeze(0).repeat(batch_size, 1, 1)  # Shape: (B, T, T)\n","\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=causal_mask, return_attn=True)\n","        # Verify the causal mask\n","        for b in range(batch_size):\n","            for l in range(num_layers):\n","                for h in range(num_heads):\n","                    attn_weights = alpha[b, l, h]  # Shape: (T, T)\n","                    # Positions where j > i should have zero attention weights\n","                    # We can create a boolean mask for j > i\n","                    future_mask = torch.triu(torch.ones(num_tokens, num_tokens), diagonal=1).bool()  # Shape: (T, T)\n","                    # Extract attention weights for future positions\n","                    future_attn = attn_weights[future_mask]\n","                    # Assert that these weights are close to zero\n","                    assert torch.all(future_attn < 1e-6), f\"Causal mask violated in batch {b}, layer {l}, head {h}\"\n","\n","perform_transformer_test_cases()"]},{"cell_type":"markdown","metadata":{"id":"71JjXvWBjXr9"},"source":["# Positional Embeddings"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733855767818,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"NdkBbHmsjY5R"},"outputs":[],"source":["class AbsoluteTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Absolute positional embedding module for input data\n","  Will bucket each input token based on the timestamp\n","  Simple lookup-table embedding based on the bucketed timestamp\n","  Adapted from 6.7920 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, dim: int, max_T: int):\n","    # max_T            maximum timestep bucket in any datapoint\n","    # dim              embedding dimension, should match dimension of input tensor (WITH timestamp)\n","    super().__init__()\n","\n","    self.pos_E = nn.Embedding(max_T, dim-1)\n","    self.max_T = max_T\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs shape: (B x T x dim)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # embs          the embedded tokens, shape (B x T x dim-1)\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    # NOTE: CHANGE HOW TO ROUND TIMESTAMPS (by minute? by 30 sec? etc.)\n","    timestamps = inputs[:, :, 0] # shape: (B, T,)\n","    timestamps = torch.round(timestamps / 10000).int() # 10 SECOND BUCKETS\n","    timestamps = torch.clamp(timestamps, min=0, max=self.max_T)\n","    #########\n","    embs = self.pos_E(timestamps) # shape: (B, T, dim-1)\n","    return embs\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":118,"status":"ok","timestamp":1733855770520,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"aqr2GqCEQqIz"},"outputs":[],"source":["class AbsoluteTimeNN(nn.Module):\n","  def __init__(self, dim: int, hidden_n: int, out_dim: int):\n","    super().__init__()\n","\n","    self.net = nn.Sequential(\n","        nn.Linear(dim, hidden_n),\n","        nn.GELU(),\n","        nn.Linear(hidden_n, out_dim)\n","    )\n","\n","  def forward(self, inputs: torch.Tensor):\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","    return self.net(timestamps)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733855770520,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"On8FNhmxnpQu"},"outputs":[],"source":["class SinuisoidalTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Sinuisoidal absolute positional embedding module for input data\n","  Adapted from \"Attention is all you need\" 2017 by Vaswani et al.\n","  Instead of using \"pos\" as the position in the vector, we use the \"pos\" = \"timestamp\"\n","\n","  https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n","  \"\"\"\n","  def __init__(self, omega=10000.0):\n","    super().__init__()\n","\n","    self.omega = 10000.0\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # pe            the embedded tokens, shape (B x T x D-1)\n","    B, T, d_inp = inputs.shape\n","    d_inp -= 1\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","    #####\n","\n","    # NOTE: i believe we can adjust this to adjust granularity, similar to how we can adjust how granular our timestamp bucketing is\n","    div_term = torch.exp(torch.arange(0, d_inp, 2) * (-math.log(self.omega) / d_inp)).to(inputs.device)\n","    pe = torch.zeros(B, T, d_inp).to(inputs.device)\n","    pe[:, :, 0::2] = torch.sin(timestamps * div_term)\n","    if d_inp % 2 == 1:\n","      pe[:, :, 1::2] = torch.cos(timestamps * div_term[:-1])\n","    else:\n","      pe[:, :, 1::2] = torch.cos(timestamps * div_term)\n","\n","    return pe\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733855773110,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"weaeW2Vevc_s"},"outputs":[],"source":["class RelativeTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Relative Positional Embedding but using timestamps instead of position\n","  Adapted from paper \"Self-Attention with Relative Position Representations\" 2018 by Vaswani et al.\n","  To produce the relative time representations (a_ij) between timestamps i and j\n","  \"\"\"\n","  def __init__(self, n_hidden: int, max_T: int):\n","    # n_hidden   number of hidden units, should match the hidden units of the transformer\n","    # max_T      maximum possible sequence length\n","    super().__init__()\n","\n","    self.max_T = max_T\n","    self.rel_K = nn.Embedding(2*max_T+1, n_hidden)\n","    self.rel_V = nn.Embedding(2*max_T+1, n_hidden)\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # rel_K         the relative time representation used in KEY ops, shape (B x T x T x n_hidden)\n","    # rel_V         the relative time representation used in VALUE ops, shape (B x T x T x n_hidden)\n","    B = inputs.shape[0]\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","\n","    time_diffs = timestamps - timestamps.transpose(2, 1) # shape: (B, T, T)\n","\n","    # NOTE: change depending on how to round and clip\n","    time_diffs = torch.round(time_diffs / 10000).int() # 10 SECOND BUCKETS\n","    time_diffs = torch.clamp(time_diffs, min=-self.max_T, max=self.max_T)\n","    time_diffs = time_diffs + self.max_T\n","    ######\n","\n","    rel_K = self.rel_K(time_diffs)\n","    rel_V = self.rel_V(time_diffs)\n","\n","    return rel_K, rel_V\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":173,"status":"ok","timestamp":1733855775999,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"z6O8KINFTTD5"},"outputs":[],"source":["# NOTE: THIS DOESN'T WORK BECAUSE IDK RESHAPING CAUSES EXTRA MEMORY ALLOCATION ISSUES AND IDK HOW TO FIX\n","class RelativeTimeNN(nn.Module):\n","  \"\"\"\n","  Relative Positional Embedding but using timestamps instead of position\n","  Adapted from paper \"Self-Attention with Relative Position Representations\" 2018 by Vaswani et al.\n","  To produce the relative time representations (a_ij) between timestamps i and j\n","  \"\"\"\n","  def __init__(self, dim: int, n_hidden: int): #, max_T: int):\n","    # n_hidden   number of hidden units, should match the hidden units of the transformer\n","    # max_T      maximum possible sequence length\n","    super().__init__()\n","\n","    # self.max_T = max_T\n","    self.n_hidden = n_hidden\n","    self.rel_K_net = nn.Sequential(\n","        nn.Linear(dim, n_hidden),\n","        nn.GELU(),\n","        nn.Linear(n_hidden, n_hidden)\n","    )\n","    self.rel_V_net = nn.Sequential(\n","        nn.Linear(dim, n_hidden),\n","        nn.GELU(),\n","        nn.Linear(n_hidden, n_hidden)\n","    )\n","    # self.rel_K = nn.Embedding(2*max_T+1, n_hidden)\n","    # self.rel_V = nn.Embedding(2*max_T+1, n_hidden)\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # rel_K         the relative time representation used in KEY ops, shape (B x T x T x n_hidden)\n","    # rel_V         the relative time representation used in VALUE ops, shape (B x T x T x n_hidden)\n","    B = inputs.shape[0]\n","    T = inputs.shape[1]\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","\n","    time_diffs = timestamps - timestamps.transpose(2, 1) # shape: (B, T, T)\n","    # time_diffs = time_diffs / 10000 # in units of 10 seconds\n","    # time_diffs = torch.clamp(time_diffs, min=-self.max_T, max=self.max_T)\n","\n","    time_diffs = time_diffs.unsqueeze(-1)\n","\n","    rel_K, rel_V = self.rel_K_net(time_diffs), self.rel_V_net(time_diffs)\n","\n","    del time_diffs\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return rel_K, rel_V\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3VEym8Mb6icn"},"source":["# Final Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1733855776153,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"Byr0V4aTbt21"},"outputs":[],"source":["MAX_T = 412"]},{"cell_type":"code","execution_count":110,"metadata":{"executionInfo":{"elapsed":105,"status":"ok","timestamp":1733877853508,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"CamcVt1NwQnd"},"outputs":[],"source":["class ShepADoodle(nn.Module):\n","  \"\"\"\n","  Adopted from 6.7960 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, emb_type: str, max_T: int, dim: int, hidden_dim: int, summary_dim: int, attn_dim: int, mlp_dim: int, num_heads: int, num_layers: int, num_classes: int):\n","    # pos_E            indicate what kind of time embedding to use\n","    #                  'none': no embedding\n","    #                  'abs': absolute time embedding\n","    #                  'sin': sinusoidal time embedding\n","    #                  'rel': relative time embedding\n","    # max_T            maximum timestamp (rounded integer)\n","    # dim              embedding dimension\n","    # attn_dim         the hidden dimension of the attention layer\n","    # mlp_dim          the hidden layer dimension of the FFN\n","    # num_heads        the number of heads in the attention layer\n","    # num_layers       the number of attention layers.\n","    super().__init__()\n","\n","    self.emb_type = emb_type\n","    self.num_classes = num_classes\n","\n","    pos_E_dim = hidden_dim + 1 # Dense vector representation + timestamp\n","    self.pos_E = None\n","    if emb_type == 'abs':\n","      self.pos_E = AbsoluteTimeEmbedding(dim=pos_E_dim, max_T=MAX_T) # 403 * 10 seconds max\n","      dim -= 1\n","    elif emb_type == 'abs_nn':\n","      self.pos_E = AbsoluteTimeNN(dim=1, hidden_n=mlp_dim, out_dim=pos_E_dim-1)\n","      dim -= 1\n","    elif emb_type == 'sin':\n","      self.pos_E = SinuisoidalTimeEmbedding()\n","      dim -= 1\n","    elif emb_type == 'rel':\n","      self.pos_E = RelativeTimeEmbedding(n_hidden=attn_dim, max_T=MAX_T) # 403 * 10 seconds max\n","      dim -= 1\n","    elif emb_type == 'rel_nn':\n","      # self.pos_E = RelativeTimeNN(dim=1, n_hidden=attn_dim, max_T=403)\n","      self.pos_E = RelativeTimeNN(dim=1, n_hidden=attn_dim)\n","      dim -= 1\n","\n","    self.input_embed = nn.Sequential(\n","        nn.LayerNorm(dim),\n","        nn.Linear(dim, hidden_dim, bias=False),\n","    )\n","\n","    self.transformer = Transformer(dim=hidden_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=num_heads, num_layers=num_layers)\n","\n","    # self.norm = nn.LayerNorm(dim)\n","\n","    # self.summary_embed = FFN(10 * summary_dim, mlp_dim)\n","\n","    # self.head = nn.Linear(dim + 10*summary_dim, 10*self.num_classes)\n","\n","    self.norm = nn.LayerNorm(hidden_dim)\n","\n","    self.summary_embed = nn.Linear(10*summary_dim, hidden_dim, bias=False)\n","\n","    # self.head = nn.Linear(hidden_dim + 10*summary_dim, 10*self.num_classes)\n","    self.head = nn.Sequential(\n","        nn.Linear(2*hidden_dim, 2*hidden_dim),\n","        nn.GELU(),\n","        nn.Linear(2*hidden_dim, 10*self.num_classes)\n","    )\n","\n","  def forward(self, inputs: torch.Tensor, summary_inputs: torch.Tensor, return_attn=False) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    # summary_inputs  batch of summary level inputs, not sequential. shape: (B x 10 x summary_dim)\n","    # return_attn   whether to return the attention weights\n","    #\n","    # Output\n","    # out           (B, 31, 10) - for given match, 31 possible classes for 10 players\n","    # alphas        the attention weights if return_attn is True. Otherwise None shape: (B, num_layers, num_heads, T, T)\n","\n","    # Embed/Reduce dimensionality of input before passing it into positional embedder.\n","    if self.emb_type != 'none':\n","      timestamps = inputs[:, :, 0]\n","      features = inputs[:, :, 1:]\n","      emb_inputs = self.input_embed(features)\n","      # Add timestamps back\n","      inputs = torch.cat((timestamps.unsqueeze(-1), emb_inputs), dim=-1)\n","    else:\n","      inputs = self.input_embed(inputs)\n","\n","    embs = None\n","    B = inputs.shape[0]\n","\n","    if self.pos_E is not None:\n","      embs = self.pos_E(inputs) # emb shape: (B, T, D-1)\n","      inputs = inputs[:, :, 1:] # get rid of timestamp info\n","      if self.emb_type == 'rel' or self.emb_type == 'rel_nn':\n","        rel_K, rel_V = embs # emb shape: (B, T, T, attn_dim)\n","        emb_inputs = inputs\n","      else:\n","        emb_inputs = inputs + embs\n","    else:\n","      emb_inputs = inputs\n","\n","    # Causal attention mask since we are implicitly time ordered (and also handle padding lol)\n","    causal_attn_mask = torch.tril(torch.ones((max_T, max_T))).expand(B, -1, -1).to(inputs.device)\n","\n","    # emb_inputs = self.input_embed(emb_inputs) # shape: (B, T, hidden_dim)\n","    if self.emb_type == 'rel' or self.emb_type == 'rel_nn':\n","      x, alphas = self.transformer(emb_inputs, attn_mask=causal_attn_mask, return_attn=return_attn, relation_aware=True, rel_K=rel_K, rel_V=rel_V)\n","      # del rel_V, rel_K #rel_V_flat, rel_K_flat, time_diffs\n","      # torch.cuda.empty_cache()\n","      # gc.collect()\n","    else:\n","      x, alphas = self.transformer(emb_inputs, attn_mask=causal_attn_mask, return_attn=return_attn, relation_aware=False)\n","    # x shape: (B, T, dim)\n","    x = x.mean(dim=1) # shape: (B, dim)\n","    x = self.norm(x) # shape: (B, dim)\n","\n","    summary = self.summary_embed(summary_inputs.flatten(start_dim=1)) # shape: (B, 10*summary_dim)\n","\n","    x = torch.cat((x, summary), dim=-1) # shape: (B, dim + 10*summary_dim)\n","\n","    out = self.head(x)\n","    out = out.reshape(B, self.num_classes, 10)\n","    return out, alphas # out: (B, 31, 10)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KmlNMAMy4a5_"},"source":["# Loss Function"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1733855782541,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"fhC9DLGz4e8H"},"outputs":[],"source":["class LeagueLoss(nn.Module):\n","  \"\"\"\n","  Adapted from 6.7960 HW3\n","  \"\"\"\n","  def __init__(self):\n","    super().__init__()\n","    self.criterion = nn.CrossEntropyLoss()\n","\n","  def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n","    # logits      the logits produced by ShepADoodle. shape: (B x 31 x 10)\n","    # input_ids   the token ids. shape: (B x 10)\n","    loss = self.criterion(logits, labels)\n","    return loss\n"]},{"cell_type":"markdown","metadata":{"id":"G2zNumADDRx_"},"source":["# Load Data"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":585,"status":"ok","timestamp":1733855791307,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"3Ea6NFdlDS2S"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","from google.colab import drive\n","import os\n","import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15092,"status":"ok","timestamp":1733855807932,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"6D4Efl2YTK4O","outputId":"39d72646-6e80-42a6-e90a-c8ef2f48ce8c"},"outputs":[],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1733855816818,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"IQrp8UH8qvs_"},"outputs":[],"source":["input_folder = '/content/drive/My Drive/LoL Data/inputs/'\n","label_folder = '/content/drive/My Drive/LoL Data/labels/'\n","summary_input_folder = '/content/drive/My Drive/LoL Data/summary_inputs/'"]},{"cell_type":"markdown","metadata":{"id":"5QhNgPN53ZOk"},"source":["## testing stuff / extracting info from data"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":102247,"status":"ok","timestamp":1733802149952,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"J3bp98XlTUc8"},"outputs":[],"source":["inp_files = os.listdir(input_folder)\n","input_files = [os.path.join(input_folder, f) for f in inp_files]\n","summary_input_files = [os.path.join(summary_input_folder, f) for f in inp_files]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1733802187410,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"IPQZHNoqqCya","outputId":"476af992-7d30-4561-8662-19c906577236"},"outputs":[],"source":["print(len(inp_files), len(summary_input_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueQE7GCBtjQT","outputId":"3aaee3c3-b1de-48ee-8a5e-1da4d7ed959e"},"outputs":[],"source":["def load_parquet_max(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy()[:, :8].max(axis=0)\n","\n","def load_parquet_min(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy()[:, :8].min(axis=0)\n","\n","input_maxes = np.zeros((8,))\n","input_mins = np.ones((8,)) * float('inf')\n","for input_file in input_files:\n","  input_maxes = np.maximum(input_maxes, load_parquet_max(input_file))\n","  input_mins = np.minimum(input_mins, load_parquet_min(input_file))\n","\n","# with ThreadPoolExecutor() as executor:\n","#     max_T = max(executor.map(load_parquet, input_files))\n","print(input_maxes)\n","print(input_mins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"RZRkUo5euxf_","outputId":"d5e59db2-56f2-4118-d1d7-b501ea280f4b"},"outputs":[],"source":["summary_normalizing_cols = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'gameEndedInSurrender', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']\n","POSITION_MAP = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","ping_cols = ['allInPings',\n"," 'assistMePings',\n"," 'basicPings',\n"," 'commandPings',\n"," 'dangerPings',\n"," 'enemyMissingPings',\n"," 'enemyVisionPings',\n"," 'getBackPings',\n"," 'holdPings',\n"," 'needVisionPings',\n"," 'onMyWayPings',\n"," 'pushPings',\n"," 'retreatPings',\n"," 'visionClearedPings']\n","def load_parquet_max(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    # print(df)\n","    # df['teamPosition'] = df['teamPosition'].map(POSITION_MAP)\n","    # df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)\n","    # summary_input_data = summary_input_data.to_numpy().astype(np.float32) # (10, 29)\n","    df['totalPings'] = df[ping_cols].sum(axis=1)\n","    df = df[summary_normalizing_cols].to_numpy()\n","    return df.max(axis=0)\n","\n","def load_parquet_min(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    # df['teamPosition'] = df['teamPosition'].map(POSITION_MAP)\n","    # df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)\n","    # summary_input_data = summary_input_data.to_numpy().astype(np.float32) # (10, 29)\n","    df['totalPings'] = df[ping_cols].sum(axis=1)\n","    df = df[summary_normalizing_cols].to_numpy()\n","    return df.min(axis=0)\n","\n","summary_input_maxes = np.zeros((len(summary_normalizing_cols),))\n","summary_input_mins = np.zeros((len(summary_normalizing_cols),))\n","for input_file in tqdm.tqdm(summary_input_files):\n","  summary_input_maxes = np.maximum(summary_input_maxes, load_parquet_max(input_file))\n","  summary_input_mins = np.maximum(summary_input_mins, load_parquet_min(input_file))\n","\n","# with ThreadPoolExecutor() as executor:\n","#     max_T = max(executor.map(load_parquet, input_files))\n","print(summary_input_maxes)\n","print(summary_input_mins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hgkpbmu25nge","outputId":"8180ea74-7b0b-43e9-c959-02c61bb914de"},"outputs":[],"source":["print(summary_input_maxes)\n","print(summary_input_mins)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWn_jShQYmUz"},"outputs":[],"source":["def load_parquet(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy().shape[0]\n","\n","with ThreadPoolExecutor() as executor:\n","    max_T = max(executor.map(load_parquet, input_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJ15i_aRaQgG","outputId":"652bbbeb-711b-4d70-8030-a56079c83aa6"},"outputs":[],"source":["max_T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhsnPUDImZNM"},"outputs":[],"source":["def load_parquet(file_path):\n","    length = pd.read_parquet(file_path, engine=\"pyarrow\").to_numpy().shape[0]\n","    if length > 1200:\n","      return 1\n","    return 0\n","\n","with ThreadPoolExecutor() as executor:\n","    n_large = sum(executor.map(load_parquet, input_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGg6LRbmnD3T","outputId":"ef28de60-3ac0-4945-c3be-5529a8705d50"},"outputs":[],"source":["n_large"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCl39NGggvJ_","outputId":"51f438c0-bfe0-4fe2-9e6f-9ed863ac6ec8"},"outputs":[],"source":["max_T"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lP9Ozlk-jVRA","outputId":"9e3f26b6-706e-4661-bb7a-9f398b2be984"},"outputs":[],"source":["len(input_files)"]},{"cell_type":"markdown","metadata":{"id":"sx0Q9luq3yFZ"},"source":["## more test stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5daTFcmDVY1"},"outputs":[],"source":["# drive.mount('/content/drive')\n","file_path = '/content/drive/My Drive/LoL Data/exp_summary_inputs/NA1_5176336691.parquet'\n","df = pd.read_parquet(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"FwxfwYl-xU46","outputId":"d5ce5de9-e460-4682-ea09-51b10d7922bd"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7s3yeQ6SRPA_"},"outputs":[],"source":["position_map = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","df['teamPosition'] = df['teamPosition'].map(position_map)\n","df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhWxBYwSTiBB"},"outputs":[],"source":["ping_cols = [col for col in df.columns if \"Pings\" in col]\n","df['totalPings'] = df[ping_cols].sum(axis=1)\n","# df.drop(ping_cols, axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-pHPJ_AVmQw","outputId":"152633a4-2b07-4774-c49e-f50fbe320cd3"},"outputs":[],"source":["ping_cols"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"lJa_YP1wHit-","outputId":"724aedd9-0c92-4ad6-f6b1-b69eba1e0fc3"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VV0-DdCiShtY","outputId":"9a0de30a-183d-4e14-c20c-ee0564afc146"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrccBOqwSUG_"},"outputs":[],"source":["normalizing_columns = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'gameEndedInSurrender', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"Bub5kao7szW9","outputId":"b406c81f-b271-4541-d1b6-6ade3573be38"},"outputs":[],"source":["# df[normalizing_columns] = df[normalizing_columns] - np.arange(len(normalizing_columns))\n","df[normalizing_columns] = df[normalizing_columns] - np.arange(len(normalizing_columns))\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NLYdwOyUAqh","outputId":"424618ea-1f8f-4884-b733-7761a30f33e7"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","np.concatenate((scaler.fit_transform(df[normalizing_columns]), df[['teamId', 'teamPosition']].to_numpy()), axis=1).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5XC32x6VB43","outputId":"937c0530-53f0-4e01-a833-940aee2e7237"},"outputs":[],"source":["df[['teamId', 'teamPosition']].to_numpy().shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0_iAveCGvH7","outputId":"46bfce7b-d772-4889-b1f8-5f868cf64c2e"},"outputs":[],"source":["df['teamPosition'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":994},"id":"Zcalt4pYGXK9","outputId":"d45471e1-1cad-42e8-eed4-6ad8694f588e"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ws_O5wI22W74"},"outputs":[],"source":["file_path = '/content/drive/My Drive/LoL Data/exp_inputs/NA1_5176336691.parquet'\n","df = pd.read_parquet(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"8iTRQ_N92Ykh","outputId":"6b2ba3cb-421d-44d3-8140-9d22de3ed296"},"outputs":[],"source":["df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"584WUW3CRhOz"},"outputs":[],"source":["arr1 = df.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oow8AQxvr-_I","outputId":"0c95fc4d-5155-4744-900c-cf9f562fec5b"},"outputs":[],"source":["arr1[:, :4]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9O3K5dVUriyL","outputId":"58418bf3-8dd7-4724-8b52-2ee2359d48af"},"outputs":[],"source":["mins = [1,2,3,4]\n","diffs = [1,2,3,4]\n","arr1[:, :4] - mins"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcE4TykrSIEp","outputId":"e67e9450-dd1c-4ea7-aeb8-5b957daf138f"},"outputs":[],"source":["np.stack([arr1, arr2], axis=0).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQInzX_wlFlN","outputId":"8ef34106-9b0c-46a8-a303-d2c525e4d92e"},"outputs":[],"source":["np.pad(arr1, pad_width=((0, 3), (0, 0)), mode='constant', constant_values=0).shape"]},{"cell_type":"markdown","metadata":{"id":"fWBUApkJ3cfO"},"source":["## RUN THIS"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4350,"status":"ok","timestamp":1733855842915,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"TKVpupElh3fF"},"outputs":[],"source":["dfs = []\n","label_csvs = os.listdir(label_folder)\n","for label_csv in label_csvs:\n","  df = pd.read_csv(os.path.join(label_folder, label_csv))\n","  dfs.append(df)\n","label_df = pd.concat(dfs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1733855848467,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"JX0RiqeIpxv7","outputId":"063615f6-2f50-48a6-c00c-daf667ed9323"},"outputs":[],"source":["label_df[label_df['match_id'] == 'NA1_5177674379'].to_numpy()[0, 1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1733802613006,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"FjBA5fl9r3ye","outputId":"bb10dfe5-0844-4843-f94f-d80e92bd16a2"},"outputs":[],"source":["label_df"]},{"cell_type":"markdown","metadata":{"id":"t0cto0-54s5h"},"source":["## RUN THIS FOR FIRST TIME OR NO MATCH_IDS"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":116174,"status":"ok","timestamp":1733855976566,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"Sj8BoQQIqdcN"},"outputs":[],"source":["match_ids = os.listdir(input_folder)\n","match_ids = [f.split('.')[0] for f in match_ids]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733855976566,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"hGhj7RQ6u288","outputId":"761a78f1-ef53-4f93-dbe2-ab105bd381cc"},"outputs":[],"source":["label_df[label_df['match_id'] == 'NA1_5177195624']"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":666615,"status":"ok","timestamp":1733859520178,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"EGnVE4alGBaL"},"outputs":[],"source":["def load_parquet(match_id):\n","    summary_df = pd.read_parquet(os.path.join(summary_input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\")\n","    summary_df['teamPosition'] = summary_df['teamPosition'].map(POSITION_MAP)\n","    # Check for None values\n","    if summary_df.isnull().values.any():\n","      return None\n","\n","    df = pd.read_parquet(os.path.join(input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    length = df.to_numpy().shape[0]\n","    if length <= 0:\n","      return None\n","    try:\n","      label = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64)\n","    except:\n","      return None\n","    if -1 in label:\n","      return None\n","    return match_id\n","\n","with ThreadPoolExecutor(max_workers=10) as executor:\n","    new_match_ids = list(executor.map(load_parquet, match_ids))\n","\n","match_ids = [m for m in new_match_ids if m is not None]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZguXCb_E6FN6"},"outputs":[],"source":["# T_CUTOFF = 1200\n","# def load_parquet(match_id):\n","#     length = pd.read_parquet(os.path.join(input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\").to_numpy().shape[0]\n","#     if length > T_CUTOFF:\n","#       return None\n","#     label = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64)\n","#     if -1 in label:\n","#       return None\n","#     return match_id\n","\n","# with ThreadPoolExecutor() as executor:\n","#     new_match_ids = list(executor.map(load_parquet, match_ids))\n","\n","# match_ids = [m for m in new_match_ids if m is not None]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1733859650219,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"KpbztDmaVuIZ","outputId":"564951f8-af36-4772-932f-9b99da47400f"},"outputs":[],"source":["len(match_ids)"]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1733859656182,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"L0twstWafvJl"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL Data/match_ids/match_ids.npy'\n","with open(save_path, 'wb') as f:\n","  np.save(f, np.array(match_ids))"]},{"cell_type":"markdown","metadata":{"id":"3WaBHXS04xB4"},"source":["## LOAD MATCH_IDS"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":127,"status":"ok","timestamp":1733859743985,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"HmrWRfosgIA2"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL Data/match_ids/match_ids.npy'\n","with open(save_path, 'rb') as f:\n","  match_ids = np.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733859744100,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"7rxPWEcCyTDn","outputId":"cc225299-4900-4bfe-bc89-349f04a426ff"},"outputs":[],"source":["len(match_ids)"]},{"cell_type":"markdown","metadata":{"id":"6ZIbKiv3NOqI"},"source":["### DON'T RUN NEXT CELL ONLY FOR TESTING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRNEoDRNuN5N"},"outputs":[],"source":["#### FOR TESTING PURPOSES\n","match_ids = np.random.choice(match_ids, size=100, replace=False)"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1733859746697,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"D_TFoxCBYonx"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733859746817,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"pAgsgbMgsTSf"},"outputs":[],"source":["train_ids, val_ids = train_test_split(\n","    match_ids, test_size=0.3, random_state=42\n",")\n","\n","val_ids, test_ids = train_test_split(\n","    val_ids, test_size=0.33, random_state=42\n",")"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":168,"status":"ok","timestamp":1733859747559,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"HlzV52e6YNHq"},"outputs":[],"source":["# MAX_T = 1500\n","# MAX_T = 1200\n","# MAX_T = 1000\n","MAX_T = 412\n","POSITION_MAP = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","ping_cols = ['allInPings',\n"," 'assistMePings',\n"," 'basicPings',\n"," 'commandPings',\n"," 'dangerPings',\n"," 'enemyMissingPings',\n"," 'enemyVisionPings',\n"," 'getBackPings',\n"," 'holdPings',\n"," 'needVisionPings',\n"," 'onMyWayPings',\n"," 'pushPings',\n"," 'retreatPings',\n"," 'visionClearedPings']\n","\n","summary_normalizing_cols = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']\n","\n","# len 8 numpy array\n","input_data_mins = np.array(\n","    [3.42520000e+04, -1.00000000e+00, -1.00000000e+00, 0.00000000e+00, 5.00573990e+02, 0.00000000e+00, 6.51923942e-02, 0.00000000e+00]\n",")\n","input_data_maxes = np.array(\n","    [4.02087200e+06, 1.46400000e+04, 1.47060000e+04, 8.00000000e+02, 3.74424520e+04, 6.42440200e+02, 5.07452965e+04, 1.00000000e+00]\n",")\n","\n","# numpy array\n","summary_input_mins = np.array(\n","    [11, 12, 14, 16530, 22541, 96, 708, 30, 3, 4, 12, 51]\n",")\n","summary_input_maxes = np.array(\n","    [39, 31, 40, 30052, 39838, 541, 2901, 229, 31, 44, 194, 334]\n",")\n","\n","class LoLDataset(Dataset):\n","    def __init__(self, match_ids):\n","      self.match_ids = match_ids\n","      # self.max_T = max_T\n","\n","    def __len__(self):\n","      return len(self.match_ids)\n","\n","    def __getitem__(self, idx):\n","      datapoint = self._load_data(self.match_ids[idx])\n","      return datapoint\n","\n","    def _load_data(self, match_id):\n","      input_file = os.path.join(input_folder, f\"{match_id}.parquet\")\n","      summary_input_file = os.path.join(summary_input_folder, f\"{match_id}.parquet\")\n","\n","      input_data = pd.read_parquet(input_file, engine=\"pyarrow\")\n","      input_data = input_data[(input_data['feature_12'] == 0) & (input_data['feature_13'] == 0)].to_numpy() # ignore ward events\n","      input_data[:, 1:8] = (input_data[:, 1:8] - input_data_mins[1:]) / (input_data_maxes[1:] - input_data_mins[1:]) # FOR NOW IGNORE TIMESTAMP NORMALIZATION FOR EMBEDDING PURPOSES\n","      if input_data.shape[0] > MAX_T:\n","        print('HELLO HELLO HELLO')\n","        raise Exception(\"loading match with greater than 1500 events\")\n","      input_data = np.pad(input_data, pad_width=((0, MAX_T - input_data.shape[0]), (0, 0)), mode='constant', constant_values=0).astype(np.float32) # (max_T, 50)\n","\n","      summary_input_data = pd.read_parquet(summary_input_file, engine=\"pyarrow\")\n","      summary_input_data['teamPosition'] = summary_input_data['teamPosition'].map(POSITION_MAP)\n","      summary_input_data['gameEndedInSurrender'] = summary_input_data['gameEndedInSurrender'].astype(int)\n","      summary_input_data['totalPings'] = summary_input_data[ping_cols].sum(axis=1)\n","      summary_input_data.drop(ping_cols, axis=1, inplace=True)\n","\n","      summary_input_data[summary_normalizing_cols] = (summary_input_data[summary_normalizing_cols] - summary_input_mins) / (summary_input_maxes - summary_input_mins)\n","      summary_input_data = summary_input_data.to_numpy().astype(np.float32)\n","\n","      # NORMALIZE DATA\n","      # (10, 16)\n","\n","      labels = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64) # (10,)\n","\n","      # print(input_data.shape)\n","      # print(summary_input_data.shape)\n","      # print(labels.shape)\n","\n","      return {'input_data': input_data, 'summary_input_data': summary_input_data, 'labels': labels}"]},{"cell_type":"code","execution_count":77,"metadata":{"executionInfo":{"elapsed":144,"status":"ok","timestamp":1733859749781,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"Thv-3psKrgk8"},"outputs":[],"source":["train_dataset = LoLDataset(train_ids)\n","val_dataset = LoLDataset(val_ids)\n","test_dataset = LoLDataset(test_ids)"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":128,"status":"ok","timestamp":1733859752224,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"bwWX3D_lrgpF"},"outputs":[],"source":["BATCH_SIZE = 32\n","N_WORKERS = 2\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1733858441531,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"DdxtQPq2A3a6","outputId":"9ea4a5c8-8df1-4679-818e-80688a554650"},"outputs":[],"source":["train_dataset[0]['summary_input_data']"]},{"cell_type":"markdown","metadata":{"id":"n7oxnr-mDWBP"},"source":["# Training"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":94,"status":"ok","timestamp":1733806321394,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"CfoOB6LeyK1K"},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":80,"metadata":{"executionInfo":{"elapsed":132,"status":"ok","timestamp":1733859758523,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"XrBPScd5DWqv"},"outputs":[],"source":["# set up the model and optimizer\n","\n","import torch.optim as optim\n","\n","max_T = MAX_T\n","dim = 50\n","attn_dim = 128\n","mlp_dim = 256\n","summary_dim = 16\n","num_classes = 31\n","hidden_dim = 10\n","\n","# no_embedding = ShepADoodle(emb_type='none', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# sin_embedding = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","model = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, hidden_dim=hidden_dim, summary_dim=summary_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6, num_classes=num_classes).cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","NUM_EPOCHS = 15\n","optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"]},{"cell_type":"code","execution_count":81,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1733859772551,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"cbdlPHZ61V8Q"},"outputs":[],"source":["model_name = \"sin\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5609152,"status":"ok","timestamp":1733865381701,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"Y5gRZDvqF_AH","outputId":"a634711a-d946-40db-dcc7-35d645ce4430"},"outputs":[],"source":["# Training\n","import tqdm\n","\n","train_losses = []\n","val_losses = []\n","for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n","    loss_meter = AverageMeter()\n","    # train_batch_losses = []\n","    for datapoint in tqdm.tqdm(train_dataloader):\n","        # torch.cuda.empty_cache()\n","        # get the inputs;\n","        inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","        # print(raw_inputs.shape)\n","\n","        # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","        if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","          inputs[:, :, 0] = inputs[:, :, 0] / 4.02087200e+06\n","\n","        inputs = inputs.cuda()\n","        summary_inputs = summary_inputs.cuda()\n","        labels = labels.cuda()\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","        # Check for NaNs\n","        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n","            print(\"NaN or Inf detected in model output\")\n","            break\n","\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","        loss_meter.update(loss.item(), inputs.shape[0])\n","        # with torch.cuda.stream(stream_ma|in):\n","        # train_batch_losses.append(loss.item())\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    scheduler.step()\n","    # val_batch_losses = []\n","    val_meter = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","      for datapoint in tqdm.tqdm(val_dataloader):\n","          # torch.cuda.empty_cache()\n","          inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","          # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","          if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","            inputs[:, :, 0] = inputs[:, :, 0] / (4.02087200e+06)\n","\n","          inputs = inputs.cuda()\n","          summary_inputs = summary_inputs.cuda()\n","          labels = labels.cuda()\n","\n","          outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","          loss = criterion(outputs, labels)\n","          val_meter.update(loss.item(), inputs.shape[0])\n","        # with to?rch.cuda.stream(stream_main):\n","        # val_batch_losses.append(loss.item())\n","\n","    # torch.cuda.synchronize()\n","    # val_loss = np.mean(val_batch_losses)\n","\n","    # train_losses.append(train_loss)\n","    # val_losses.append(val_loss)\n","    # print(f\"Train Epoch: {epoch}, Training Loss: {train_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    # print(f\"Train Epoch: {epoch}, Validation Loss: {val_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    train_losses.append(loss_meter.calculate())\n","    val_losses.append(val_meter.calculate())\n","    print(f\"Train Epoch: {epoch}, Training Loss: {loss_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    print(f\"Train Epoch: {epoch}, Validation Loss: {val_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_epoch_{epoch}.pt'\n","    torch.save(model.state_dict(), save_path)\n","\n","    model.train()\n"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1733865382013,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"92xoDWWAgBWC"},"outputs":[],"source":["model_name = \"sin\"\n","save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_final.pt'\n","torch.save(model.state_dict(), save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43624,"status":"ok","timestamp":1733871478417,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"x5ku8AiK9kWI","outputId":"7e4c7334-cbba-4dc2-8f1c-8474d3b876a7"},"outputs":[],"source":["test_meter = AverageMeter()\n","for datapoint in tqdm.tqdm(test_dataloader):\n","  inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","  # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","  if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","    inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","  inputs = inputs.cuda()\n","  summary_inputs = summary_inputs.cuda()\n","  labels = labels.cuda()\n","\n","  outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","  loss = criterion(outputs, labels)\n","  test_meter.update(loss.item(), inputs.shape[0])\n","\n","test_loss = test_meter.calculate()\n","print(f\"Test Loss: {test_meter.calculate():0.4f}\")"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733871478417,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"8FwAzrgEQBf5"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/train_losses.npy'\n","np.save(save_path, np.array(train_losses))"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733871478417,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"RHWF0P3OQFFy"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/val_losses.npy'\n","np.save(save_path, np.array(val_losses))"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1733871478417,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"m0_pWkBASg4E"},"outputs":[],"source":["class LoLDataset8(Dataset):\n","    def __init__(self, match_ids):\n","      self.match_ids = match_ids\n","      # self.max_T = max_T\n","\n","    def __len__(self):\n","      return len(self.match_ids)\n","\n","    def __getitem__(self, idx):\n","      datapoint = self._load_data(self.match_ids[idx])\n","      return datapoint\n","\n","    def _load_data(self, match_id):\n","      input_file = os.path.join(input_folder, f\"{match_id}.parquet\")\n","      summary_input_file = os.path.join(summary_input_folder, f\"{match_id}.parquet\")\n","\n","      input_data = pd.read_parquet(input_file, engine=\"pyarrow\")\n","      input_data = input_data[(input_data['feature_12'] == 0) & (input_data['feature_13'] == 0)].to_numpy() # ignore ward events\n","      input_data[:, 1:8] = (input_data[:, 1:8] - input_data_mins[1:]) / (input_data_maxes[1:] - input_data_mins[1:]) # FOR NOW IGNORE TIMESTAMP NORMALIZATION FOR EMBEDDING PURPOSES\n","      if input_data.shape[0] > MAX_T:\n","        print('HELLO HELLO HELLO')\n","        raise Exception(\"loading match with greater than 1500 events\")\n","      input_data = np.pad(input_data, pad_width=((0, MAX_T - input_data.shape[0]), (0, 0)), mode='constant', constant_values=0).astype(np.float32) # (max_T, 50)\n","\n","      summary_input_data = pd.read_parquet(summary_input_file, engine=\"pyarrow\")\n","      summary_input_data['teamPosition'] = summary_input_data['teamPosition'].map(POSITION_MAP)\n","      summary_input_data['gameEndedInSurrender'] = summary_input_data['gameEndedInSurrender'].astype(int)\n","      summary_input_data['totalPings'] = summary_input_data[ping_cols].sum(axis=1)\n","      summary_input_data.drop(ping_cols, axis=1, inplace=True)\n","\n","      summary_input_data[summary_normalizing_cols] = (summary_input_data[summary_normalizing_cols] - summary_input_mins) / (summary_input_maxes - summary_input_mins)\n","      summary_input_data = summary_input_data.to_numpy().astype(np.float32)\n","\n","      # NORMALIZE DATA\n","      # (10, 16)\n","\n","      labels = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64) # (10,)\n","      labels = np.floor(labels / 4).astype(np.int64)\n","\n","      # print(input_data.shape)\n","      # print(summary_input_data.shape)\n","      # print(labels.shape)\n","\n","      return {'input_data': input_data, 'summary_input_data': summary_input_data, 'labels': labels}\n","\n","train_dataset8 = LoLDataset8(train_ids)\n","val_dataset8 = LoLDataset8(val_ids)\n","test_dataset8 = LoLDataset8(test_ids)\n","\n","BATCH_SIZE = 32\n","N_WORKERS = 2\n","train_dataloader8 = DataLoader(train_dataset8, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","val_dataloader8 = DataLoader(val_dataset8, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","test_dataloader8 = DataLoader(test_dataset8, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS, pin_memory=True)"]},{"cell_type":"code","execution_count":117,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1733884091298,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"qYEv3s6lIzBu"},"outputs":[],"source":["import torch.optim as optim\n","\n","max_T = MAX_T\n","dim = 50\n","attn_dim = 128\n","mlp_dim = 256\n","summary_dim = 16\n","# PREDICT ONLY RANK INSTEAD\n","num_classes = 8\n","hidden_dim = 10\n","\n","# no_embedding = ShepADoodle(emb_type='none', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# sin_embedding = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","model = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, hidden_dim=hidden_dim, summary_dim=summary_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6, num_classes=num_classes).cuda()\n","model_name = \"abs\"\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","NUM_EPOCHS = 15\n","optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5816509,"status":"ok","timestamp":1733889913455,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"rvGUx-yw5o6N","outputId":"d730881c-a7ee-48e6-ef80-6f655d86be75"},"outputs":[],"source":["# Training\n","import tqdm\n","\n","train_losses = []\n","val_losses = []\n","for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n","    loss_meter = AverageMeter()\n","    # train_batch_losses = []\n","    for datapoint in tqdm.tqdm(train_dataloader8):\n","        # get the inputs;\n","        inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","        # print(raw_inputs.shape)\n","\n","        # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","        if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","          inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","        inputs = inputs.cuda()\n","        summary_inputs = summary_inputs.cuda()\n","        labels = labels.cuda()\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # print(inputs.shape)\n","        # print(summary_inputs.shape)\n","\n","        # forward + backward + optimize\n","        outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","        loss_meter.update(loss.item(), inputs.shape[0])\n","        # with torch.cuda.stream(stream_main):\n","        # train_batch_losses.append(loss.item())\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    # val_batch_losses = []\n","    val_meter = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","      for datapoint in tqdm.tqdm(val_dataloader8):\n","          # torch.cuda.empty_cache()\n","          inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","          # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","          if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","            inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","          inputs = inputs.cuda()\n","          summary_inputs = summary_inputs.cuda()\n","          labels = labels.cuda()\n","\n","          outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","          loss = criterion(outputs, labels)\n","          val_meter.update(loss.item(), inputs.shape[0])\n","        # with to?rch.cuda.stream(stream_main):\n","        # val_batch_losses.append(loss.item())\n","\n","    # torch.cuda.synchronize()\n","    # val_loss = np.mean(val_batch_losses)\n","\n","    # train_losses.append(train_loss)\n","    # val_losses.append(val_loss)\n","    # print(f\"Train Epoch: {epoch}, Training Loss: {train_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    # print(f\"Train Epoch: {epoch}, Validation Loss: {val_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    train_losses.append(loss_meter.calculate())\n","    val_losses.append(val_meter.calculate())\n","    print(f\"Train Epoch: {epoch}, Training Loss: {loss_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    print(f\"Train Epoch: {epoch}, Validation Loss: {val_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_epoch_{epoch}.pt'\n","    torch.save(model.state_dict(), save_path)\n","\n","    model.train()"]},{"cell_type":"code","execution_count":120,"metadata":{"executionInfo":{"elapsed":160,"status":"ok","timestamp":1733890178983,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"9IDfVVAl7R9z"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_final.pt'\n","torch.save(model.state_dict(), save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43183,"status":"ok","timestamp":1733890226436,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"lkup-Xg_8OHj","outputId":"83ed7a7b-70fd-49f4-e0d1-d9af053c0f11"},"outputs":[],"source":["test_meter = AverageMeter()\n","for datapoint in tqdm.tqdm(test_dataloader8):\n","  inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","  # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","  if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","    inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","  inputs = inputs.cuda()\n","  summary_inputs = summary_inputs.cuda()\n","  labels = labels.cuda()\n","\n","  outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","  loss = criterion(outputs, labels)\n","  test_meter.update(loss.item(), inputs.shape[0])\n","\n","test_loss = test_meter.calculate()\n","print(f\"Test Loss: {test_meter.calculate():0.4f}\")"]},{"cell_type":"code","execution_count":122,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733890226436,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"V3AQ4vZxANsE"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/train_losses.npy'\n","np.save(save_path, np.array(train_losses))"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733890226436,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"vDApfYLD8jlt"},"outputs":[],"source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/val_losses.npy'\n","np.save(save_path, np.array(val_losses))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":1915,"status":"error","timestamp":1733892817926,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"9QjOxMkvDdsG","outputId":"1a62c2e9-3910-489e-bf2e-ffa192ebf270"},"outputs":[],"source":["model.eval()\n","\n","with torch.no_grad():\n","  for datapoint in tqdm.tqdm(test_dataloader):\n","    inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","    outputs, _ = model(inputs=inputs.cuda(), summary_inputs=summary_inputs.cuda())\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1733892893909,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"so754ki-ECIK","outputId":"23f6717b-8c48-4d26-9b16-acd411139d2e"},"outputs":[],"source":["torch.max(nn.functional.softmax(outputs))"]},{"cell_type":"markdown","metadata":{"id":"GRcdLqtXPuwu"},"source":["# Testing stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rk3JVmXIaGJ","outputId":"8708ca7d-57e3-484e-cd8f-110ea2ddcd98"},"outputs":[],"source":["# import gc\n","# import torch\n","\n","# List all tensors\n","for obj in gc.get_objects():\n","    if torch.is_tensor(obj):\n","        print(f\"Tensor: {obj.shape}, dtype: {obj.dtype}, device: {obj.device}, size: {obj.element_size() * obj.nelement() / 1e6}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AB-sE-DJbDT","outputId":"5d15a347-fe25-41bb-9d89-755e8d0e02df"},"outputs":[],"source":["# model = Net()\n","for name, param in model.named_parameters():\n","    print(name, param.size(), param.element_size() * param.nelement() / 1e6)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONLnQNlkzDr5","outputId":"74816135-0487-4f13-a28d-7bcc70e1d835"},"outputs":[],"source":["len(train_ids), len(val_ids), len(test_ids)"]},{"cell_type":"markdown","metadata":{"id":"FDC_IPI3ICs8"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1733877385080,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"ROs1QhWYIEAu"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1733877386232,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"Au2R14f38_PH","outputId":"cd5bcb23-f382-41c1-e91e-0ecdeafc0af9"},"outputs":[],"source":["print(f\"FINAL LOSSES: TRAIN {train_losses[-1]}, VAL {val_losses[-1]}, TEST {test_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1733877388362,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"rszs4oy_9LMr","outputId":"4f430dd0-436d-458a-f34d-00612af6b943"},"outputs":[],"source":["plt.plot(train_losses, label='train')\n","plt.plot(val_losses, label='val')\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss (averaged over all batches)')\n","plt.show()"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":67,"status":"ok","timestamp":1733824548925,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"K5T1j-QWzRv7"},"outputs":[],"source":["def contains_nan(tensor):\n","    return torch.isnan(tensor).any()\n","\n","\n","def check_dataloader_for_nan(dataloader):\n","    for batch_idx, batch in enumerate(dataloader):\n","        if isinstance(batch, (tuple, list)):  # If batch is a tuple or list (e.g., data, label)\n","            for i, item in enumerate(batch):\n","                if isinstance(item, torch.Tensor) and contains_nan(item):\n","                    print(f\"NaN found in batch {batch_idx}, item {i}\")\n","                    return True\n","        elif isinstance(batch, torch.Tensor):  # If batch itself is a tensor\n","            if contains_nan(batch):\n","                print(f\"NaN found in batch {batch_idx}\")\n","                return True\n","    print(\"No NaNs found in the DataLoader.\")\n","    return False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274569,"status":"ok","timestamp":1733824833953,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"hmqgAl6I_p5w","outputId":"a62bd4dd-229b-473f-fa6e-fa01ff14f4da"},"outputs":[],"source":["check_dataloader_for_nan(train_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79203,"status":"ok","timestamp":1733824913459,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"p_DcArh0_zig","outputId":"d63d39da-b164-4438-c2cb-f9114472657a"},"outputs":[],"source":["check_dataloader_for_nan(val_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":331282,"status":"error","timestamp":1733825244733,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"},"user_tz":300},"id":"3gP2S3QJ_0uu","outputId":"584a594c-b671-40da-8674-bccc47e9c805"},"outputs":[],"source":["check_dataloader_for_nan(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8JU0AOw_1mH"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
