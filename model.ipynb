{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"cQ2CgtHpipTJ","executionInfo":{"status":"ok","timestamp":1733855756331,"user_tz":300,"elapsed":1543,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from typing import Tuple, Union, Optional, List\n","# import torchvision\n","# import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n"]},{"cell_type":"code","source":["class AverageMeter():\n","    def __init__(self):\n","        self.num = 0\n","        self.tot = 0\n","\n","    def update(self, val: float, sz: float):\n","        self.num += val*sz\n","        self.tot += sz\n","\n","    def calculate(self) -> float:\n","        return self.num/self.tot"],"metadata":{"id":"MtAKMsC6HX9M","executionInfo":{"status":"ok","timestamp":1733855756331,"user_tz":300,"elapsed":1,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Base Transformer Implementation"],"metadata":{"id":"4fZ6lHpejSmG"}},{"cell_type":"code","source":["class AttentionHead(nn.Module):\n","  \"\"\"\n","  Adapted from 6.7920 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, dim: int, n_hidden: int, relation_aware=False):\n","      # dim: the dimension of the input\n","      # n_hidden: the dimension of the keys, queries, and values\n","\n","      super().__init__()\n","\n","      self.W_K = nn.Linear(dim, n_hidden) # W_K weight matrix\n","      self.W_Q = nn.Linear(dim, n_hidden) # W_Q weight matrix\n","      self.W_V = nn.Linear(dim, n_hidden) # W_V weight matrix\n","      self.n_hidden = n_hidden\n","\n","  def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor], relation_aware: Optional[bool], rel_K: Optional[torch.Tensor], rel_V: Optional[torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n","      # x                the inputs. shape: (B x T x dim)\n","      # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","      #                  contains 1 if (in batch b) token i should attend on token j and 0\n","      #                  otherwise. shape: (B x T x T)\n","      # rel_k and rel_V  the relative time representations, if relation_aware is False then ingore\n","      #                  shape: (B x T x T x n_hidden)\n","      #\n","      # Outputs:\n","      # attn_output      the output of performing self-attention on x. shape: (Batch x Num_tokens x n_hidden)\n","      # alpha            the attention weights (after softmax). shape: (B x T x T)\n","      #\n","\n","      out, alpha = None, None\n","      # TODO: Compute self attention on x.\n","      #       (1) First project x to the query Q, key K, value V.\n","      #       (2) Then compute the attention weights alpha as:\n","      #                  alpha = softmax(QK^T/sqrt(n_hidden))\n","      #           Make sure to take into account attn_mask such that token i does not attend on token\n","      #           j if attn_mask[b, i, j] == 0. (Hint, in such a case, what value should you set the weight\n","      #           to before the softmax so that after the softmax the value is 0?)\n","      #       (3) The output is a linear combination of the values (weighted by the alphas):\n","      #                  out = alpha V\n","      #       (4) return the output and the alpha after the softmax\n","\n","      # ======= Answer START ========\n","      Q = self.W_Q(x) # Shape: B x T x n_hidden\n","      K = self.W_K(x)\n","      V = self.W_V(x)\n","\n","      alpha = (Q @ K.transpose(1, 2)) / np.sqrt(self.n_hidden) # Shape: B x T x T\n","\n","      if relation_aware:\n","        alpha += torch.einsum('btd,btid->bti', Q, rel_K) # Shape: B x T x T\n","\n","      if attn_mask is not None:\n","        alpha[attn_mask == 0] = -float('inf')\n","\n","      # alpha = alpha.flatten(start_dim=1).softmax(dim=1).reshape(alpha.shape)\n","      alpha = alpha.softmax(dim=-1)\n","      # B x T^2 -> B x T\n","\n","      attn_output = alpha @ V # Shape: B x T x n_hidden\n","      if relation_aware:\n","        # attn_output += alpha * rel_V # Shape: B x T x n_hidden\n","        attn_output += torch.einsum('bti,btid->btd', alpha, rel_V) # Shape: B x T x n_hidden\n","      # ======= Answer  END ========\n","\n","      return attn_output#, alpha\n"],"metadata":{"id":"CDGO8d3zjC9L","executionInfo":{"status":"ok","timestamp":1733855756475,"user_tz":300,"elapsed":2,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class MultiHeadedAttention(nn.Module):\n","    \"\"\"\n","    Adapted from 6.7920 Fall 2024 HW3\n","    \"\"\"\n","    def __init__(self, dim: int, n_hidden: int, num_heads: int):\n","        # dim: the dimension of the input\n","        # n_hidden: the hidden dimenstion for the attention layer\n","        # num_heads: the number of attention heads\n","        super().__init__()\n","\n","        # TODO: set up your parameters for multi-head attention. You should initialize\n","        #       num_heads attention heads (see nn.ModuleList) as well as a linear layer\n","        #       that projects the concatenated outputs of each head into dim\n","        #       (what size should this linear layer be?)\n","\n","        # ======= Answer START ========\n","        self.attn_heads = nn.ModuleList([AttentionHead(dim, n_hidden) for _ in range(num_heads)])\n","        self.linear = nn.Linear(num_heads * n_hidden, dim)\n","        # ======= Answer  END ========\n","\n","    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor], relation_aware=False, rel_K=None, rel_V=None) -> Tuple[torch.Tensor, torch.Tensor]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","        #                  contains 1 if (in batch b) token i should attend on token j and 0\n","        #                  otherwise. shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      the output of performing multi-headed self-attention on x.\n","        #                  shape: (B x T x dim)\n","        # attn_alphas      the attention weights of each of the attention heads.\n","        #                  shape: (B x Num_heads x T x T)\n","\n","        attn_output, attn_alphas = None, None\n","\n","        # TODO: Compute multi-headed attention. Loop through each of your attention heads\n","        #       and collect the outputs. Concatenate them together along the hidden dimension,\n","        #       and then project them back into the output dimension (dim). Return both\n","        #       the final attention outputs as well as the alphas from each head.\n","\n","        # ======= Answer START ========\n","        B, T, _ = x.shape\n","        attn_outputs = torch.zeros((B, T, 0)).to(x.device) # device=x.device)\n","        attn_alphas = torch.zeros((B, 0, T, T)).to(x.device) # device=x.device)\n","        for head in self.attn_heads:\n","          # attn_output, attn_alpha = head(x, attn_mask, relation_aware, rel_K, rel_V)\n","          attn_output = head(x, attn_mask, relation_aware, rel_K, rel_V)\n","          attn_outputs = torch.cat((attn_outputs, attn_output), dim=-1) # concatenate the (B, T, n_hidden) tensor along last dim\n","          # attn_alphas = torch.cat((attn_alphas, attn_alpha.unsqueeze(1)), dim=1) # concat (B, 1, T, T) tensor along dimension 1\n","\n","        attn_output = self.linear(attn_outputs) # linear layer on a (B, T, n_hidden*num_heads) tensor into (B, T, n_hidden)\n","        # ======= Answer END ========\n","        return attn_output#, attn_alphas"],"metadata":{"id":"ZjSUqhY5jFua","executionInfo":{"status":"ok","timestamp":1733855762478,"user_tz":300,"elapsed":151,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# these are already implemented for you!\n","\n","class FFN(nn.Module):\n","    def __init__(self, dim: int, n_hidden: int):\n","        # dim       the dimension of the input\n","        # n_hidden  the width of the linear layer\n","\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, n_hidden),\n","            nn.GELU(),\n","            nn.Linear(n_hidden, dim),\n","        )\n","\n","    def forward(self, x: torch.Tensor)-> torch.Tensor:\n","        # x         the input. shape: (B x T x dim)\n","\n","        # Outputs:\n","        # out       the output of the feed-forward network: (B x T x dim)\n","        return self.net(x)\n","\n","class AttentionResidual(nn.Module):\n","    def __init__(self, dim: int, attn_dim: int, mlp_dim: int, num_heads: int):\n","        # dim       the dimension of the input\n","        # attn_dim  the hidden dimension of the attention layer\n","        # mlp_dim   the hidden layer of the FFN\n","        # num_heads the number of heads in the attention layer\n","        super().__init__()\n","        self.attn = MultiHeadedAttention(dim, attn_dim, num_heads)\n","        self.ffn = FFN(dim, mlp_dim)\n","\n","    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor, relation_aware=False, rel_K=None, rel_V=None) -> Tuple[torch.Tensor, torch.Tensor]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. If None, ignore. If not None, then mask[b, i, j]\n","        #                  contains 1 if (in batch b) token i should attend on token j and 0\n","        #                  otherwise. shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      shape: (B x T x dim)\n","        # attn_alphas      the attention weights of each of the attention heads.\n","        #                  shape: (B x Num_heads x T x T)\n","\n","        # attn_out, alphas = self.attn(x=x, attn_mask=attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","        attn_out = self.attn(x=x, attn_mask=attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","        x = attn_out + x\n","        x = self.ffn(x) + x\n","        return x#, alphas"],"metadata":{"id":"naVlSlo1FHZf","executionInfo":{"status":"ok","timestamp":1733855762478,"user_tz":300,"elapsed":2,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    \"\"\"\n","    Adapted from 6.7920 Fall 2024 HW3\n","    \"\"\"\n","    def __init__(self, dim: int, attn_dim: int, mlp_dim: int, num_heads: int, num_layers: int):\n","        # dim       the dimension of the input\n","        # attn_dim  the hidden dimension of the attention layer\n","        # mlp_dim   the hidden layer of the FFN\n","        # num_heads the number of heads in the attention layer\n","        # num_layers the number of attention layers.\n","        super().__init__()\n","\n","        # TODO: set up the parameters for the transformer!\n","        #       You should set up num_layers of AttentionResiduals\n","        #       nn.ModuleList will be helpful here.\n","\n","        # ======= Answer START ========\n","        self.layers = nn.ModuleList([AttentionResidual(dim, attn_dim, mlp_dim, num_heads) for _ in range(num_layers)])\n","        # ======= Answer END ========\n","\n","    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor, relation_aware=False, rel_K=None, rel_V=None, return_attn=False)-> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","        # x                the inputs. shape: (B x T x dim)\n","        # attn_mask        an attention mask. Pass this to each of the AttentionResidual layers!\n","        #                  shape: (B x T x T)\n","        #\n","        # Outputs:\n","        # attn_output      shape: (B x T x dim)\n","        # attn_alphas      If return_attn is False, return None. Otherwise return the attention weights\n","        #                  of each of each of the attention heads for each of the layers.\n","        #                  shape: (B x Num_layers x Num_heads x T x T)\n","\n","        output, collected_attns = None, None\n","\n","        # TODO: Implement the transformer forward pass! Pass the input successively through each of the\n","        # AttentionResidual layers. If return_attn is True, collect the alphas along the way.\n","\n","        # ======= Answer START ========\n","        for layer in self.layers:\n","          # x, attn = layer(x, attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","          x = layer(x, attn_mask, relation_aware=relation_aware, rel_K=rel_K, rel_V=rel_V)\n","          # if return_attn:\n","          #   if collected_attns is None:\n","          #     collected_attns = attn.unsqueeze(1) # initialize as a (B, 1, num_heads, T, T) tensor\n","          #   else:\n","          #     collected_attns = torch.cat((collected_attns, attn.unsqueeze(1)), dim=1) # concatenate along first dimension\n","        output = x\n","        # ======= Answer END ========\n","\n","        return output, collected_attns"],"metadata":{"id":"E0Hw_fRdjIw2","executionInfo":{"status":"ok","timestamp":1733855764580,"user_tz":300,"elapsed":3,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def perform_transformer_test_cases():\n","    num_tokens = 100\n","    batch_size = 10\n","    dim = 64\n","    num_layers = 4\n","    num_heads = 2\n","    dummy_model = Transformer(dim=dim, attn_dim=32, mlp_dim=dim, num_heads=num_heads, num_layers=num_layers).cuda()\n","\n","    inp = torch.randn(batch_size, num_tokens, dim).cuda()\n","\n","    # test case 1 regular forward pass\n","    print(\"Test Case 1\")\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=None)\n","        assert alpha is None\n","        assert output.shape == (batch_size, num_tokens, dim), f\"wrong output shape {output.shape}\"\n","\n","    # test case 2 collect attentions\n","    print(\"Test Case 2\")\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=None, return_attn=True)\n","        assert output.shape == (batch_size, num_tokens, dim), f\"wrong output shape {output.shape}\"\n","        assert alpha.shape == (batch_size, num_layers, num_heads, num_tokens, num_tokens), f\"wrong alpha shape {alpha.shape}\"\n","\n","    print(\"Test Case 3\")\n","    # test case 3 with attention mask\n","    attn_mask = torch.zeros(batch_size, num_tokens, num_tokens).cuda()\n","    attn_mask[:, torch.arange(num_tokens), torch.arange(num_tokens)] = 1\n","    attn_mask[:, torch.arange(num_tokens)[1:], torch.arange(num_tokens)[:-1]] = 1\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=attn_mask, return_attn=True)\n","        print(\"Attention mask pattern\", attn_mask[0])\n","        print(\"Alpha pattern\", alpha[0, 0, 0])\n","        assert torch.all(alpha.permute(1, 2, 0, 3, 4)[:, :, attn_mask == 0] == 0).item()\n","\n","    print(\"Test Case 4\")\n","    # test case 4 creates a causal mask where each token can only attend to previous tokens and itself\n","    causal_mask = torch.tril(torch.ones(num_tokens, num_tokens)).unsqueeze(0).repeat(batch_size, 1, 1)  # Shape: (B, T, T)\n","\n","    with torch.no_grad():\n","        output, alpha = dummy_model(inp, attn_mask=causal_mask, return_attn=True)\n","        # Verify the causal mask\n","        for b in range(batch_size):\n","            for l in range(num_layers):\n","                for h in range(num_heads):\n","                    attn_weights = alpha[b, l, h]  # Shape: (T, T)\n","                    # Positions where j > i should have zero attention weights\n","                    # We can create a boolean mask for j > i\n","                    future_mask = torch.triu(torch.ones(num_tokens, num_tokens), diagonal=1).bool()  # Shape: (T, T)\n","                    # Extract attention weights for future positions\n","                    future_attn = attn_weights[future_mask]\n","                    # Assert that these weights are close to zero\n","                    assert torch.all(future_attn < 1e-6), f\"Causal mask violated in batch {b}, layer {l}, head {h}\"\n","\n","perform_transformer_test_cases()"],"metadata":{"id":"e13_Ce8_jNDD","colab":{"base_uri":"https://localhost:8080/","height":332},"outputId":"620f1c6f-2c27-411c-8569-b953e4bf5472","executionInfo":{"status":"error","timestamp":1733855765260,"user_tz":300,"elapsed":682,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Case 1\n","Test Case 2\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7e6e9b6835ad>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_attn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Causal mask violated in batch {b}, layer {l}, head {h}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mperform_transformer_test_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-7e6e9b6835ad>\u001b[0m in \u001b[0;36mperform_transformer_test_cases\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_attn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"wrong output shape {output.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"wrong alpha shape {alpha.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Case 3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]},{"cell_type":"markdown","source":["# Positional Embeddings"],"metadata":{"id":"71JjXvWBjXr9"}},{"cell_type":"code","source":["class AbsoluteTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Absolute positional embedding module for input data\n","  Will bucket each input token based on the timestamp\n","  Simple lookup-table embedding based on the bucketed timestamp\n","  Adapted from 6.7920 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, dim: int, max_T: int):\n","    # max_T            maximum timestep bucket in any datapoint\n","    # dim              embedding dimension, should match dimension of input tensor (WITH timestamp)\n","    super().__init__()\n","\n","    self.pos_E = nn.Embedding(max_T, dim-1)\n","    self.max_T = max_T\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs shape: (B x T x dim)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # embs          the embedded tokens, shape (B x T x dim-1)\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    # NOTE: CHANGE HOW TO ROUND TIMESTAMPS (by minute? by 30 sec? etc.)\n","    timestamps = inputs[:, :, 0] # shape: (B, T,)\n","    timestamps = torch.round(timestamps / 10000).int() # 10 SECOND BUCKETS\n","    timestamps = torch.clamp(timestamps, min=0, max=self.max_T)\n","    #########\n","    embs = self.pos_E(timestamps) # shape: (B, T, dim-1)\n","    return embs\n"],"metadata":{"id":"NdkBbHmsjY5R","executionInfo":{"status":"ok","timestamp":1733855767818,"user_tz":300,"elapsed":1,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class AbsoluteTimeNN(nn.Module):\n","  def __init__(self, dim: int, hidden_n: int, out_dim: int):\n","    super().__init__()\n","\n","    self.net = nn.Sequential(\n","        nn.Linear(dim, hidden_n),\n","        nn.GELU(),\n","        nn.Linear(hidden_n, out_dim)\n","    )\n","\n","  def forward(self, inputs: torch.Tensor):\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","    return self.net(timestamps)"],"metadata":{"id":"aqr2GqCEQqIz","executionInfo":{"status":"ok","timestamp":1733855770520,"user_tz":300,"elapsed":118,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class SinuisoidalTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Sinuisoidal absolute positional embedding module for input data\n","  Adapted from \"Attention is all you need\" 2017 by Vaswani et al.\n","  Instead of using \"pos\" as the position in the vector, we use the \"pos\" = \"timestamp\"\n","\n","  https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n","  \"\"\"\n","  def __init__(self, omega=10000.0):\n","    super().__init__()\n","\n","    self.omega = 10000.0\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # pe            the embedded tokens, shape (B x T x D-1)\n","    B, T, d_inp = inputs.shape\n","    d_inp -= 1\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","    #####\n","\n","    # NOTE: i believe we can adjust this to adjust granularity, similar to how we can adjust how granular our timestamp bucketing is\n","    div_term = torch.exp(torch.arange(0, d_inp, 2) * (-math.log(self.omega) / d_inp)).to(inputs.device)\n","    pe = torch.zeros(B, T, d_inp).to(inputs.device)\n","    pe[:, :, 0::2] = torch.sin(timestamps * div_term)\n","    if d_inp % 2 == 1:\n","      pe[:, :, 1::2] = torch.cos(timestamps * div_term[:-1])\n","    else:\n","      pe[:, :, 1::2] = torch.cos(timestamps * div_term)\n","\n","    return pe\n","\n","\n"],"metadata":{"id":"On8FNhmxnpQu","executionInfo":{"status":"ok","timestamp":1733855770520,"user_tz":300,"elapsed":2,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class RelativeTimeEmbedding(nn.Module):\n","  \"\"\"\n","  Relative Positional Embedding but using timestamps instead of position\n","  Adapted from paper \"Self-Attention with Relative Position Representations\" 2018 by Vaswani et al.\n","  To produce the relative time representations (a_ij) between timestamps i and j\n","  \"\"\"\n","  def __init__(self, n_hidden: int, max_T: int):\n","    # n_hidden   number of hidden units, should match the hidden units of the transformer\n","    # max_T      maximum possible sequence length\n","    super().__init__()\n","\n","    self.max_T = max_T\n","    self.rel_K = nn.Embedding(2*max_T+1, n_hidden)\n","    self.rel_V = nn.Embedding(2*max_T+1, n_hidden)\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # rel_K         the relative time representation used in KEY ops, shape (B x T x T x n_hidden)\n","    # rel_V         the relative time representation used in VALUE ops, shape (B x T x T x n_hidden)\n","    B = inputs.shape[0]\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","\n","    time_diffs = timestamps - timestamps.transpose(2, 1) # shape: (B, T, T)\n","\n","    # NOTE: change depending on how to round and clip\n","    time_diffs = torch.round(time_diffs / 10000).int() # 10 SECOND BUCKETS\n","    time_diffs = torch.clamp(time_diffs, min=-self.max_T, max=self.max_T)\n","    time_diffs = time_diffs + self.max_T\n","    ######\n","\n","    rel_K = self.rel_K(time_diffs)\n","    rel_V = self.rel_V(time_diffs)\n","\n","    return rel_K, rel_V\n","\n","\n"],"metadata":{"id":"weaeW2Vevc_s","executionInfo":{"status":"ok","timestamp":1733855773110,"user_tz":300,"elapsed":1,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# NOTE: THIS DOESN'T WORK BECAUSE IDK RESHAPING CAUSES EXTRA MEMORY ALLOCATION ISSUES AND IDK HOW TO FIX\n","class RelativeTimeNN(nn.Module):\n","  \"\"\"\n","  Relative Positional Embedding but using timestamps instead of position\n","  Adapted from paper \"Self-Attention with Relative Position Representations\" 2018 by Vaswani et al.\n","  To produce the relative time representations (a_ij) between timestamps i and j\n","  \"\"\"\n","  def __init__(self, dim: int, n_hidden: int): #, max_T: int):\n","    # n_hidden   number of hidden units, should match the hidden units of the transformer\n","    # max_T      maximum possible sequence length\n","    super().__init__()\n","\n","    # self.max_T = max_T\n","    self.n_hidden = n_hidden\n","    self.rel_K_net = nn.Sequential(\n","        nn.Linear(dim, n_hidden),\n","        nn.GELU(),\n","        nn.Linear(n_hidden, n_hidden)\n","    )\n","    self.rel_V_net = nn.Sequential(\n","        nn.Linear(dim, n_hidden),\n","        nn.GELU(),\n","        nn.Linear(n_hidden, n_hidden)\n","    )\n","    # self.rel_K = nn.Embedding(2*max_T+1, n_hidden)\n","    # self.rel_V = nn.Embedding(2*max_T+1, n_hidden)\n","\n","  def forward(self, inputs: torch.Tensor):\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    #               timestamp information in dimension 0 # NOTE: THIS WILL CHANGE DEPENDING ON HOW DATA COLLECTED\n","    # Output\n","    # rel_K         the relative time representation used in KEY ops, shape (B x T x T x n_hidden)\n","    # rel_V         the relative time representation used in VALUE ops, shape (B x T x T x n_hidden)\n","    B = inputs.shape[0]\n","    T = inputs.shape[1]\n","\n","    # NOTE: NEED TO CHANGE DEPENDING ON HOW INPUTS ARE\n","    timestamps = inputs[:, :, 0].unsqueeze(-1) # shape: (B, T, 1)\n","\n","    time_diffs = timestamps - timestamps.transpose(2, 1) # shape: (B, T, T)\n","    # time_diffs = time_diffs / 10000 # in units of 10 seconds\n","    # time_diffs = torch.clamp(time_diffs, min=-self.max_T, max=self.max_T)\n","\n","    time_diffs = time_diffs.unsqueeze(-1)\n","\n","    rel_K, rel_V = self.rel_K_net(time_diffs), self.rel_V_net(time_diffs)\n","\n","    del time_diffs\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return rel_K, rel_V\n","\n","\n"],"metadata":{"id":"z6O8KINFTTD5","executionInfo":{"status":"ok","timestamp":1733855775999,"user_tz":300,"elapsed":173,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Final Model"],"metadata":{"id":"3VEym8Mb6icn"}},{"cell_type":"code","source":["MAX_T = 412"],"metadata":{"id":"Byr0V4aTbt21","executionInfo":{"status":"ok","timestamp":1733855776153,"user_tz":300,"elapsed":1,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class ShepADoodle(nn.Module):\n","  \"\"\"\n","  Adopted from 6.7960 Fall 2024 HW3\n","  \"\"\"\n","  def __init__(self, emb_type: str, max_T: int, dim: int, hidden_dim: int, summary_dim: int, attn_dim: int, mlp_dim: int, num_heads: int, num_layers: int, num_classes: int):\n","    # pos_E            indicate what kind of time embedding to use\n","    #                  'none': no embedding\n","    #                  'abs': absolute time embedding\n","    #                  'sin': sinusoidal time embedding\n","    #                  'rel': relative time embedding\n","    # max_T            maximum timestamp (rounded integer)\n","    # dim              embedding dimension\n","    # attn_dim         the hidden dimension of the attention layer\n","    # mlp_dim          the hidden layer dimension of the FFN\n","    # num_heads        the number of heads in the attention layer\n","    # num_layers       the number of attention layers.\n","    super().__init__()\n","\n","    self.emb_type = emb_type\n","    self.num_classes = num_classes\n","\n","    pos_E_dim = hidden_dim + 1 # Dense vector representation + timestamp\n","    self.pos_E = None\n","    if emb_type == 'abs':\n","      self.pos_E = AbsoluteTimeEmbedding(dim=pos_E_dim, max_T=MAX_T) # 403 * 10 seconds max\n","      dim -= 1\n","    elif emb_type == 'abs_nn':\n","      self.pos_E = AbsoluteTimeNN(dim=1, hidden_n=mlp_dim, out_dim=pos_E_dim-1)\n","      dim -= 1\n","    elif emb_type == 'sin':\n","      self.pos_E = SinuisoidalTimeEmbedding()\n","      dim -= 1\n","    elif emb_type == 'rel':\n","      self.pos_E = RelativeTimeEmbedding(n_hidden=attn_dim, max_T=MAX_T) # 403 * 10 seconds max\n","      dim -= 1\n","    elif emb_type == 'rel_nn':\n","      # self.pos_E = RelativeTimeNN(dim=1, n_hidden=attn_dim, max_T=403)\n","      self.pos_E = RelativeTimeNN(dim=1, n_hidden=attn_dim)\n","      dim -= 1\n","\n","    self.input_embed = nn.Sequential(\n","        nn.LayerNorm(dim),\n","        nn.Linear(dim, hidden_dim, bias=False),\n","    )\n","\n","    self.transformer = Transformer(dim=hidden_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=num_heads, num_layers=num_layers)\n","\n","    # self.norm = nn.LayerNorm(dim)\n","\n","    # self.summary_embed = FFN(10 * summary_dim, mlp_dim)\n","\n","    # self.head = nn.Linear(dim + 10*summary_dim, 10*self.num_classes)\n","\n","    self.norm = nn.LayerNorm(hidden_dim)\n","\n","    self.summary_embed = nn.Linear(10*summary_dim, hidden_dim, bias=False)\n","\n","    # self.head = nn.Linear(hidden_dim + 10*summary_dim, 10*self.num_classes)\n","    self.head = nn.Sequential(\n","        nn.Linear(2*hidden_dim, 2*hidden_dim),\n","        nn.GELU(),\n","        nn.Linear(2*hidden_dim, 10*self.num_classes)\n","    )\n","\n","  def forward(self, inputs: torch.Tensor, summary_inputs: torch.Tensor, return_attn=False) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","    # inputs        a batch of inputs. shape: (B x T x D)\n","    # summary_inputs  batch of summary level inputs, not sequential. shape: (B x 10 x summary_dim)\n","    # return_attn   whether to return the attention weights\n","    #\n","    # Output\n","    # out           (B, 31, 10) - for given match, 31 possible classes for 10 players\n","    # alphas        the attention weights if return_attn is True. Otherwise None shape: (B, num_layers, num_heads, T, T)\n","\n","    # Embed/Reduce dimensionality of input before passing it into positional embedder.\n","    if self.emb_type != 'none':\n","      timestamps = inputs[:, :, 0]\n","      features = inputs[:, :, 1:]\n","      emb_inputs = self.input_embed(features)\n","      # Add timestamps back\n","      inputs = torch.cat((timestamps.unsqueeze(-1), emb_inputs), dim=-1)\n","    else:\n","      inputs = self.input_embed(inputs)\n","\n","    embs = None\n","    B = inputs.shape[0]\n","\n","    if self.pos_E is not None:\n","      embs = self.pos_E(inputs) # emb shape: (B, T, D-1)\n","      inputs = inputs[:, :, 1:] # get rid of timestamp info\n","      if self.emb_type == 'rel' or self.emb_type == 'rel_nn':\n","        rel_K, rel_V = embs # emb shape: (B, T, T, attn_dim)\n","        emb_inputs = inputs\n","      else:\n","        emb_inputs = inputs + embs\n","    else:\n","      emb_inputs = inputs\n","\n","    # Causal attention mask since we are implicitly time ordered (and also handle padding lol)\n","    causal_attn_mask = torch.tril(torch.ones((max_T, max_T))).expand(B, -1, -1).to(inputs.device)\n","\n","    # emb_inputs = self.input_embed(emb_inputs) # shape: (B, T, hidden_dim)\n","    if self.emb_type == 'rel' or self.emb_type == 'rel_nn':\n","      x, alphas = self.transformer(emb_inputs, attn_mask=causal_attn_mask, return_attn=return_attn, relation_aware=True, rel_K=rel_K, rel_V=rel_V)\n","      # del rel_V, rel_K #rel_V_flat, rel_K_flat, time_diffs\n","      # torch.cuda.empty_cache()\n","      # gc.collect()\n","    else:\n","      x, alphas = self.transformer(emb_inputs, attn_mask=causal_attn_mask, return_attn=return_attn, relation_aware=False)\n","    # x shape: (B, T, dim)\n","    x = x.mean(dim=1) # shape: (B, dim)\n","    x = self.norm(x) # shape: (B, dim)\n","\n","    summary = self.summary_embed(summary_inputs.flatten(start_dim=1)) # shape: (B, 10*summary_dim)\n","\n","    x = torch.cat((x, summary), dim=-1) # shape: (B, dim + 10*summary_dim)\n","\n","    out = self.head(x)\n","    out = out.reshape(B, self.num_classes, 10)\n","    return out, alphas # out: (B, 31, 10)\n","\n"],"metadata":{"id":"CamcVt1NwQnd","executionInfo":{"status":"ok","timestamp":1733877853508,"user_tz":300,"elapsed":105,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":["# Loss Function"],"metadata":{"id":"KmlNMAMy4a5_"}},{"cell_type":"code","source":["class LeagueLoss(nn.Module):\n","  \"\"\"\n","  Adapted from 6.7960 HW3\n","  \"\"\"\n","  def __init__(self):\n","    super().__init__()\n","    self.criterion = nn.CrossEntropyLoss()\n","\n","  def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n","    # logits      the logits produced by ShepADoodle. shape: (B x 31 x 10)\n","    # input_ids   the token ids. shape: (B x 10)\n","    loss = self.criterion(logits, labels)\n","    return loss\n"],"metadata":{"id":"fhC9DLGz4e8H","executionInfo":{"status":"ok","timestamp":1733855782541,"user_tz":300,"elapsed":121,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"G2zNumADDRx_"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","from google.colab import drive\n","import os\n","import tqdm"],"metadata":{"id":"3Ea6NFdlDS2S","executionInfo":{"status":"ok","timestamp":1733855791307,"user_tz":300,"elapsed":585,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6D4Efl2YTK4O","outputId":"39d72646-6e80-42a6-e90a-c8ef2f48ce8c","executionInfo":{"status":"ok","timestamp":1733855807932,"user_tz":300,"elapsed":15092,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["input_folder = '/content/drive/My Drive/LoL Data/inputs/'\n","label_folder = '/content/drive/My Drive/LoL Data/labels/'\n","summary_input_folder = '/content/drive/My Drive/LoL Data/summary_inputs/'"],"metadata":{"id":"IQrp8UH8qvs_","executionInfo":{"status":"ok","timestamp":1733855816818,"user_tz":300,"elapsed":123,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## testing stuff / extracting info from data"],"metadata":{"id":"5QhNgPN53ZOk"}},{"cell_type":"code","source":["inp_files = os.listdir(input_folder)\n","input_files = [os.path.join(input_folder, f) for f in inp_files]\n","summary_input_files = [os.path.join(summary_input_folder, f) for f in inp_files]"],"metadata":{"id":"J3bp98XlTUc8","executionInfo":{"status":"ok","timestamp":1733802149952,"user_tz":300,"elapsed":102247,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(len(inp_files), len(summary_input_files))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPQZHNoqqCya","executionInfo":{"status":"ok","timestamp":1733802187410,"user_tz":300,"elapsed":66,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"476af992-7d30-4561-8662-19c906577236"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["36413 36413\n"]}]},{"cell_type":"code","source":["def load_parquet_max(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy()[:, :8].max(axis=0)\n","\n","def load_parquet_min(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy()[:, :8].min(axis=0)\n","\n","input_maxes = np.zeros((8,))\n","input_mins = np.ones((8,)) * float('inf')\n","for input_file in input_files:\n","  input_maxes = np.maximum(input_maxes, load_parquet_max(input_file))\n","  input_mins = np.minimum(input_mins, load_parquet_min(input_file))\n","\n","# with ThreadPoolExecutor() as executor:\n","#     max_T = max(executor.map(load_parquet, input_files))\n","print(input_maxes)\n","print(input_mins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueQE7GCBtjQT","outputId":"3aaee3c3-b1de-48ee-8a5e-1da4d7ed959e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[4.02087200e+06 1.46400000e+04 1.47060000e+04 8.00000000e+02\n"," 3.74424520e+04 6.42440200e+02 5.07452965e+04 1.00000000e+00]\n","[ 3.42520000e+04 -1.00000000e+00 -1.00000000e+00  0.00000000e+00\n","  5.00573990e+02  0.00000000e+00  6.51923942e-02  0.00000000e+00]\n"]}]},{"cell_type":"code","source":["summary_normalizing_cols = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'gameEndedInSurrender', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']\n","POSITION_MAP = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","ping_cols = ['allInPings',\n"," 'assistMePings',\n"," 'basicPings',\n"," 'commandPings',\n"," 'dangerPings',\n"," 'enemyMissingPings',\n"," 'enemyVisionPings',\n"," 'getBackPings',\n"," 'holdPings',\n"," 'needVisionPings',\n"," 'onMyWayPings',\n"," 'pushPings',\n"," 'retreatPings',\n"," 'visionClearedPings']\n","def load_parquet_max(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    # print(df)\n","    # df['teamPosition'] = df['teamPosition'].map(POSITION_MAP)\n","    # df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)\n","    # summary_input_data = summary_input_data.to_numpy().astype(np.float32) # (10, 29)\n","    df['totalPings'] = df[ping_cols].sum(axis=1)\n","    df = df[summary_normalizing_cols].to_numpy()\n","    return df.max(axis=0)\n","\n","def load_parquet_min(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    # df['teamPosition'] = df['teamPosition'].map(POSITION_MAP)\n","    # df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)\n","    # summary_input_data = summary_input_data.to_numpy().astype(np.float32) # (10, 29)\n","    df['totalPings'] = df[ping_cols].sum(axis=1)\n","    df = df[summary_normalizing_cols].to_numpy()\n","    return df.min(axis=0)\n","\n","summary_input_maxes = np.zeros((len(summary_normalizing_cols),))\n","summary_input_mins = np.zeros((len(summary_normalizing_cols),))\n","for input_file in tqdm.tqdm(summary_input_files):\n","  summary_input_maxes = np.maximum(summary_input_maxes, load_parquet_max(input_file))\n","  summary_input_mins = np.maximum(summary_input_mins, load_parquet_min(input_file))\n","\n","# with ThreadPoolExecutor() as executor:\n","#     max_T = max(executor.map(load_parquet, input_files))\n","print(summary_input_maxes)\n","print(summary_input_mins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"RZRkUo5euxf_","outputId":"d5e59db2-56f2-4118-d1d7-b501ea280f4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 39%|███▊      | 4942/12810 [41:01<1:05:19,  2.01it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-39d868f0be74>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msummary_input_mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_normalizing_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_input_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0msummary_input_maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_input_maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_parquet_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0msummary_input_mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_input_mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_parquet_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-39d868f0be74>\u001b[0m in \u001b[0;36mload_parquet_max\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m  'visionClearedPings']\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_parquet_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# df['teamPosition'] = df['teamPosition'].map(POSITION_MAP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m         dataset = ParquetDataset(\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparquet_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_fragment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             self._dataset = ds.FileSystemDataset(\n\u001b[0m\u001b[1;32m   1360\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["print(summary_input_maxes)\n","print(summary_input_mins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hgkpbmu25nge","outputId":"8180ea74-7b0b-43e9-c959-02c61bb914de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[39 31 40 30052 39838 541 2901 True 229 31 44 194 334]\n","[11 12 14 16530 22541 96 708 True 30 3 4 12 51]\n"]}]},{"cell_type":"code","source":["def load_parquet(file_path):\n","    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    return df.to_numpy().shape[0]\n","\n","with ThreadPoolExecutor() as executor:\n","    max_T = max(executor.map(load_parquet, input_files))"],"metadata":{"id":"tWn_jShQYmUz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJ15i_aRaQgG","outputId":"652bbbeb-711b-4d70-8030-a56079c83aa6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["370"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["def load_parquet(file_path):\n","    length = pd.read_parquet(file_path, engine=\"pyarrow\").to_numpy().shape[0]\n","    if length > 1200:\n","      return 1\n","    return 0\n","\n","with ThreadPoolExecutor() as executor:\n","    n_large = sum(executor.map(load_parquet, input_files))"],"metadata":{"id":"jhsnPUDImZNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_large"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGg6LRbmnD3T","outputId":"ef28de60-3ac0-4945-c3be-5529a8705d50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["196"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["max_T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCl39NGggvJ_","outputId":"51f438c0-bfe0-4fe2-9e6f-9ed863ac6ec8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2392"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["len(input_files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lP9Ozlk-jVRA","outputId":"9e3f26b6-706e-4661-bb7a-9f398b2be984"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12810"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## more test stuff"],"metadata":{"id":"sx0Q9luq3yFZ"}},{"cell_type":"code","source":["# drive.mount('/content/drive')\n","file_path = '/content/drive/My Drive/LoL Data/exp_summary_inputs/NA1_5176336691.parquet'\n","df = pd.read_parquet(file_path)"],"metadata":{"id":"k5daTFcmDVY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"FwxfwYl-xU46","outputId":"d5ce5de9-e460-4682-ea09-51b10d7922bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   kills  deaths  assists  teamId teamPosition  allInPings  assistMePings  \\\n","0      5       7        8     100          TOP           0              6   \n","1      8       7       14     100       JUNGLE           2             13   \n","2      9       6        1     100       MIDDLE           1              3   \n","3     11       7       11     100       BOTTOM           0             15   \n","4     11       6       17     100      UTILITY           0              0   \n","5     10       6        6     200          TOP           4              7   \n","6      8       4       10     200       JUNGLE          27             15   \n","7      5       6       15     200       MIDDLE           0              0   \n","8      7      12        8     200       BOTTOM           0              0   \n","9      3      16       11     200      UTILITY           0              1   \n","\n","   basicPings  commandPings  dangerPings  ...  goldEarned  champLevel  \\\n","0           0             9            0  ...       15348          18   \n","1           0            21            0  ...       14855          17   \n","2           0             8            0  ...       13806          16   \n","3           0             0            0  ...       18224          18   \n","4           0             0            0  ...       13776          15   \n","5           0            21            0  ...       15425          17   \n","6           0            26            0  ...       16712          17   \n","7           0             0            0  ...       16143          18   \n","8           0            16            0  ...       14669          15   \n","9           0             0            0  ...        9989          13   \n","\n","   champExperience  totalMinionsKilled  longestTimeSpentLiving  \\\n","0            22827                 274                     597   \n","1            18296                  23                     629   \n","2            15922                 192                     880   \n","3            19538                 267                     660   \n","4            14594                  35                     572   \n","5            17849                 206                    1102   \n","6            18149                  82                     708   \n","7            19060                 219                     873   \n","8            14336                 214                     475   \n","9            11425                  30                     229   \n","\n","   gameEndedInSurrender  visionScore  visionWardsBoughtInGame  wardsKilled  \\\n","0                 False           22                        0            1   \n","1                 False           26                        2            1   \n","2                 False           15                        0            0   \n","3                 False            9                        0            0   \n","4                 False          127                        3           16   \n","5                 False           26                        3            2   \n","6                 False           47                        5           12   \n","7                 False           31                        2            7   \n","8                 False           26                        2            9   \n","9                 False           84                        0            9   \n","\n","   wardsPlaced  \n","0           12  \n","1            7  \n","2            8  \n","3            6  \n","4           64  \n","5            7  \n","6            6  \n","7            5  \n","8           11  \n","9           38  \n","\n","[10 rows x 29 columns]"],"text/html":["\n","  <div id=\"df-d01c5f64-5f35-4e19-b330-8a35c5f59283\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kills</th>\n","      <th>deaths</th>\n","      <th>assists</th>\n","      <th>teamId</th>\n","      <th>teamPosition</th>\n","      <th>allInPings</th>\n","      <th>assistMePings</th>\n","      <th>basicPings</th>\n","      <th>commandPings</th>\n","      <th>dangerPings</th>\n","      <th>...</th>\n","      <th>goldEarned</th>\n","      <th>champLevel</th>\n","      <th>champExperience</th>\n","      <th>totalMinionsKilled</th>\n","      <th>longestTimeSpentLiving</th>\n","      <th>gameEndedInSurrender</th>\n","      <th>visionScore</th>\n","      <th>visionWardsBoughtInGame</th>\n","      <th>wardsKilled</th>\n","      <th>wardsPlaced</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>100</td>\n","      <td>TOP</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15348</td>\n","      <td>18</td>\n","      <td>22827</td>\n","      <td>274</td>\n","      <td>597</td>\n","      <td>False</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>14</td>\n","      <td>100</td>\n","      <td>JUNGLE</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>14855</td>\n","      <td>17</td>\n","      <td>18296</td>\n","      <td>23</td>\n","      <td>629</td>\n","      <td>False</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>MIDDLE</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>13806</td>\n","      <td>16</td>\n","      <td>15922</td>\n","      <td>192</td>\n","      <td>880</td>\n","      <td>False</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>100</td>\n","      <td>BOTTOM</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18224</td>\n","      <td>18</td>\n","      <td>19538</td>\n","      <td>267</td>\n","      <td>660</td>\n","      <td>False</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>17</td>\n","      <td>100</td>\n","      <td>UTILITY</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>13776</td>\n","      <td>15</td>\n","      <td>14594</td>\n","      <td>35</td>\n","      <td>572</td>\n","      <td>False</td>\n","      <td>127</td>\n","      <td>3</td>\n","      <td>16</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>200</td>\n","      <td>TOP</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15425</td>\n","      <td>17</td>\n","      <td>17849</td>\n","      <td>206</td>\n","      <td>1102</td>\n","      <td>False</td>\n","      <td>26</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>200</td>\n","      <td>JUNGLE</td>\n","      <td>27</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>16712</td>\n","      <td>17</td>\n","      <td>18149</td>\n","      <td>82</td>\n","      <td>708</td>\n","      <td>False</td>\n","      <td>47</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>15</td>\n","      <td>200</td>\n","      <td>MIDDLE</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>16143</td>\n","      <td>18</td>\n","      <td>19060</td>\n","      <td>219</td>\n","      <td>873</td>\n","      <td>False</td>\n","      <td>31</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>200</td>\n","      <td>BOTTOM</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>14669</td>\n","      <td>15</td>\n","      <td>14336</td>\n","      <td>214</td>\n","      <td>475</td>\n","      <td>False</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3</td>\n","      <td>16</td>\n","      <td>11</td>\n","      <td>200</td>\n","      <td>UTILITY</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>9989</td>\n","      <td>13</td>\n","      <td>11425</td>\n","      <td>30</td>\n","      <td>229</td>\n","      <td>False</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>38</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 29 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d01c5f64-5f35-4e19-b330-8a35c5f59283')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d01c5f64-5f35-4e19-b330-8a35c5f59283 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d01c5f64-5f35-4e19-b330-8a35c5f59283');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-09e24a73-e6f9-407a-b326-cad3c4befd5a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09e24a73-e6f9-407a-b326-cad3c4befd5a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-09e24a73-e6f9-407a-b326-cad3c4befd5a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_99a38189-dc36-4187-8d72-fbf4062d30c5\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_99a38189-dc36-4187-8d72-fbf4062d30c5 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["position_map = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","df['teamPosition'] = df['teamPosition'].map(position_map)\n","df['gameEndedInSurrender'] = df['gameEndedInSurrender'].astype(int)"],"metadata":{"id":"7s3yeQ6SRPA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ping_cols = [col for col in df.columns if \"Pings\" in col]\n","df['totalPings'] = df[ping_cols].sum(axis=1)\n","# df.drop(ping_cols, axis=1, inplace=True)"],"metadata":{"id":"ZhWxBYwSTiBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ping_cols"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-pHPJ_AVmQw","outputId":"152633a4-2b07-4774-c49e-f50fbe320cd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['allInPings',\n"," 'assistMePings',\n"," 'basicPings',\n"," 'commandPings',\n"," 'dangerPings',\n"," 'enemyMissingPings',\n"," 'enemyVisionPings',\n"," 'getBackPings',\n"," 'holdPings',\n"," 'needVisionPings',\n"," 'onMyWayPings',\n"," 'pushPings',\n"," 'retreatPings',\n"," 'visionClearedPings']"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"lJa_YP1wHit-","outputId":"724aedd9-0c92-4ad6-f6b1-b69eba1e0fc3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   kills  deaths  assists  teamId  teamPosition  allInPings  assistMePings  \\\n","0      5       7        8     100             1           0              6   \n","1      8       7       14     100             2           2             13   \n","2      9       6        1     100             3           1              3   \n","3     11       7       11     100             4           0             15   \n","4     11       6       17     100             5           0              0   \n","5     10       6        6     200             1           4              7   \n","6      8       4       10     200             2          27             15   \n","7      5       6       15     200             3           0              0   \n","8      7      12        8     200             4           0              0   \n","9      3      16       11     200             5           0              1   \n","\n","   basicPings  commandPings  dangerPings  ...  champLevel  champExperience  \\\n","0           0             9            0  ...          18            22827   \n","1           0            21            0  ...          17            18296   \n","2           0             8            0  ...          16            15922   \n","3           0             0            0  ...          18            19538   \n","4           0             0            0  ...          15            14594   \n","5           0            21            0  ...          17            17849   \n","6           0            26            0  ...          17            18149   \n","7           0             0            0  ...          18            19060   \n","8           0            16            0  ...          15            14336   \n","9           0             0            0  ...          13            11425   \n","\n","   totalMinionsKilled  longestTimeSpentLiving  gameEndedInSurrender  \\\n","0                 274                     597                     0   \n","1                  23                     629                     0   \n","2                 192                     880                     0   \n","3                 267                     660                     0   \n","4                  35                     572                     0   \n","5                 206                    1102                     0   \n","6                  82                     708                     0   \n","7                 219                     873                     0   \n","8                 214                     475                     0   \n","9                  30                     229                     0   \n","\n","   visionScore  visionWardsBoughtInGame  wardsKilled  wardsPlaced  totalPings  \n","0           22                        0            1           12          98  \n","1           26                        2            1            7          87  \n","2           15                        0            0            8          53  \n","3            9                        0            0            6          39  \n","4          127                        3           16           64           5  \n","5           26                        3            2            7         132  \n","6           47                        5           12            6         169  \n","7           31                        2            7            5           4  \n","8           26                        2            9           11          19  \n","9           84                        0            9           38          40  \n","\n","[10 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-1d433abf-f9a0-4bc5-b6b7-40adfe6b8577\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kills</th>\n","      <th>deaths</th>\n","      <th>assists</th>\n","      <th>teamId</th>\n","      <th>teamPosition</th>\n","      <th>allInPings</th>\n","      <th>assistMePings</th>\n","      <th>basicPings</th>\n","      <th>commandPings</th>\n","      <th>dangerPings</th>\n","      <th>...</th>\n","      <th>champLevel</th>\n","      <th>champExperience</th>\n","      <th>totalMinionsKilled</th>\n","      <th>longestTimeSpentLiving</th>\n","      <th>gameEndedInSurrender</th>\n","      <th>visionScore</th>\n","      <th>visionWardsBoughtInGame</th>\n","      <th>wardsKilled</th>\n","      <th>wardsPlaced</th>\n","      <th>totalPings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>100</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>22827</td>\n","      <td>274</td>\n","      <td>597</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>14</td>\n","      <td>100</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>18296</td>\n","      <td>23</td>\n","      <td>629</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>16</td>\n","      <td>15922</td>\n","      <td>192</td>\n","      <td>880</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>100</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>19538</td>\n","      <td>267</td>\n","      <td>660</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>17</td>\n","      <td>100</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15</td>\n","      <td>14594</td>\n","      <td>35</td>\n","      <td>572</td>\n","      <td>0</td>\n","      <td>127</td>\n","      <td>3</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>200</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>17849</td>\n","      <td>206</td>\n","      <td>1102</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>132</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>200</td>\n","      <td>2</td>\n","      <td>27</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>18149</td>\n","      <td>82</td>\n","      <td>708</td>\n","      <td>0</td>\n","      <td>47</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>169</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>15</td>\n","      <td>200</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>19060</td>\n","      <td>219</td>\n","      <td>873</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>200</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15</td>\n","      <td>14336</td>\n","      <td>214</td>\n","      <td>475</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3</td>\n","      <td>16</td>\n","      <td>11</td>\n","      <td>200</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>13</td>\n","      <td>11425</td>\n","      <td>30</td>\n","      <td>229</td>\n","      <td>0</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>38</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d433abf-f9a0-4bc5-b6b7-40adfe6b8577')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1d433abf-f9a0-4bc5-b6b7-40adfe6b8577 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1d433abf-f9a0-4bc5-b6b7-40adfe6b8577');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7964c6a1-95c2-4a82-a5b7-7b5807b58443\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7964c6a1-95c2-4a82-a5b7-7b5807b58443')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7964c6a1-95c2-4a82-a5b7-7b5807b58443 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7e5a771b-2a82-4e67-b7a9-a21d700b8c02\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7e5a771b-2a82-4e67-b7a9-a21d700b8c02 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VV0-DdCiShtY","outputId":"9a0de30a-183d-4e14-c20c-ee0564afc146"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['kills', 'deaths', 'assists', 'teamId', 'teamPosition', 'allInPings',\n","       'assistMePings', 'basicPings', 'commandPings', 'dangerPings',\n","       'enemyMissingPings', 'enemyVisionPings', 'getBackPings', 'holdPings',\n","       'needVisionPings', 'onMyWayPings', 'pushPings', 'retreatPings',\n","       'visionClearedPings', 'goldEarned', 'champLevel', 'champExperience',\n","       'totalMinionsKilled', 'longestTimeSpentLiving', 'gameEndedInSurrender',\n","       'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced'],\n","      dtype='object')"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["normalizing_columns = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'gameEndedInSurrender', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']"],"metadata":{"id":"hrccBOqwSUG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df[normalizing_columns] = df[normalizing_columns] - np.arange(len(normalizing_columns))\n","df[normalizing_columns] = df[normalizing_columns] - np.arange(len(normalizing_columns))\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"Bub5kao7szW9","outputId":"b406c81f-b271-4541-d1b6-6ade3573be38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   kills  deaths  assists  teamId  teamPosition  allInPings  assistMePings  \\\n","0      5       6        6     100             1           0              6   \n","1      8       6       12     100             2           2             13   \n","2      9       5       -1     100             3           1              3   \n","3     11       6        9     100             4           0             15   \n","4     11       5       15     100             5           0              0   \n","5     10       5        4     200             1           4              7   \n","6      8       3        8     200             2          27             15   \n","7      5       5       13     200             3           0              0   \n","8      7      11        6     200             4           0              0   \n","9      3      15        9     200             5           0              1   \n","\n","   basicPings  commandPings  dangerPings  ...  champLevel  champExperience  \\\n","0           0             9            0  ...          18            22823   \n","1           0            21            0  ...          17            18292   \n","2           0             8            0  ...          16            15918   \n","3           0             0            0  ...          18            19534   \n","4           0             0            0  ...          15            14590   \n","5           0            21            0  ...          17            17845   \n","6           0            26            0  ...          17            18145   \n","7           0             0            0  ...          18            19056   \n","8           0            16            0  ...          15            14332   \n","9           0             0            0  ...          13            11421   \n","\n","   totalMinionsKilled  longestTimeSpentLiving  gameEndedInSurrender  \\\n","0                 269                     591                    -7   \n","1                  18                     623                    -7   \n","2                 187                     874                    -7   \n","3                 262                     654                    -7   \n","4                  30                     566                    -7   \n","5                 201                    1096                    -7   \n","6                  77                     702                    -7   \n","7                 214                     867                    -7   \n","8                 209                     469                    -7   \n","9                  25                     223                    -7   \n","\n","   visionScore  visionWardsBoughtInGame  wardsKilled  wardsPlaced  totalPings  \n","0           14                       -9           -9            1          86  \n","1           18                       -7           -9           -4          75  \n","2            7                       -9          -10           -3          41  \n","3            1                       -9          -10           -5          27  \n","4          119                       -6            6           53          -7  \n","5           18                       -6           -8           -4         120  \n","6           39                       -4            2           -5         157  \n","7           23                       -7           -3           -6          -8  \n","8           18                       -7           -1            0           7  \n","9           76                       -9           -1           27          28  \n","\n","[10 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-287017d8-20e1-4146-ba14-282a599d100a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kills</th>\n","      <th>deaths</th>\n","      <th>assists</th>\n","      <th>teamId</th>\n","      <th>teamPosition</th>\n","      <th>allInPings</th>\n","      <th>assistMePings</th>\n","      <th>basicPings</th>\n","      <th>commandPings</th>\n","      <th>dangerPings</th>\n","      <th>...</th>\n","      <th>champLevel</th>\n","      <th>champExperience</th>\n","      <th>totalMinionsKilled</th>\n","      <th>longestTimeSpentLiving</th>\n","      <th>gameEndedInSurrender</th>\n","      <th>visionScore</th>\n","      <th>visionWardsBoughtInGame</th>\n","      <th>wardsKilled</th>\n","      <th>wardsPlaced</th>\n","      <th>totalPings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>100</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>22823</td>\n","      <td>269</td>\n","      <td>591</td>\n","      <td>-7</td>\n","      <td>14</td>\n","      <td>-9</td>\n","      <td>-9</td>\n","      <td>1</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>12</td>\n","      <td>100</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>18292</td>\n","      <td>18</td>\n","      <td>623</td>\n","      <td>-7</td>\n","      <td>18</td>\n","      <td>-7</td>\n","      <td>-9</td>\n","      <td>-4</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>-1</td>\n","      <td>100</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>16</td>\n","      <td>15918</td>\n","      <td>187</td>\n","      <td>874</td>\n","      <td>-7</td>\n","      <td>7</td>\n","      <td>-9</td>\n","      <td>-10</td>\n","      <td>-3</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>100</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>19534</td>\n","      <td>262</td>\n","      <td>654</td>\n","      <td>-7</td>\n","      <td>1</td>\n","      <td>-9</td>\n","      <td>-10</td>\n","      <td>-5</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>100</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15</td>\n","      <td>14590</td>\n","      <td>30</td>\n","      <td>566</td>\n","      <td>-7</td>\n","      <td>119</td>\n","      <td>-6</td>\n","      <td>6</td>\n","      <td>53</td>\n","      <td>-7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>200</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>17845</td>\n","      <td>201</td>\n","      <td>1096</td>\n","      <td>-7</td>\n","      <td>18</td>\n","      <td>-6</td>\n","      <td>-8</td>\n","      <td>-4</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>200</td>\n","      <td>2</td>\n","      <td>27</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>18145</td>\n","      <td>77</td>\n","      <td>702</td>\n","      <td>-7</td>\n","      <td>39</td>\n","      <td>-4</td>\n","      <td>2</td>\n","      <td>-5</td>\n","      <td>157</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>200</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>19056</td>\n","      <td>214</td>\n","      <td>867</td>\n","      <td>-7</td>\n","      <td>23</td>\n","      <td>-7</td>\n","      <td>-3</td>\n","      <td>-6</td>\n","      <td>-8</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>200</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>15</td>\n","      <td>14332</td>\n","      <td>209</td>\n","      <td>469</td>\n","      <td>-7</td>\n","      <td>18</td>\n","      <td>-7</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>200</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>13</td>\n","      <td>11421</td>\n","      <td>25</td>\n","      <td>223</td>\n","      <td>-7</td>\n","      <td>76</td>\n","      <td>-9</td>\n","      <td>-1</td>\n","      <td>27</td>\n","      <td>28</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 30 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-287017d8-20e1-4146-ba14-282a599d100a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-287017d8-20e1-4146-ba14-282a599d100a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-287017d8-20e1-4146-ba14-282a599d100a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-55e0be45-4316-4ea2-ba67-0cee758a84e3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55e0be45-4316-4ea2-ba67-0cee758a84e3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-55e0be45-4316-4ea2-ba67-0cee758a84e3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_ab154911-8e3c-42a5-a814-8922e1e71994\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_ab154911-8e3c-42a5-a814-8922e1e71994 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","np.concatenate((scaler.fit_transform(df[normalizing_columns]), df[['teamId', 'teamPosition']].to_numpy()), axis=1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NLYdwOyUAqh","outputId":"424618ea-1f8f-4884-b733-7761a30f33e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 15)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["df[['teamId', 'teamPosition']].to_numpy().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5XC32x6VB43","outputId":"937c0530-53f0-4e01-a833-940aee2e7237"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 2)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["df['teamPosition'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0_iAveCGvH7","outputId":"46bfce7b-d772-4889-b1f8-5f868cf64c2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['TOP', 'JUNGLE', 'MIDDLE', 'BOTTOM', 'UTILITY'], dtype=object)"]},"metadata":{},"execution_count":129}]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":994},"id":"Zcalt4pYGXK9","outputId":"d45471e1-1cad-42e8-eed4-6ad8694f588e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["kills                        int64\n","deaths                       int64\n","assists                      int64\n","teamId                       int64\n","teamPosition               float64\n","allInPings                   int64\n","assistMePings                int64\n","basicPings                   int64\n","commandPings                 int64\n","dangerPings                  int64\n","enemyMissingPings            int64\n","enemyVisionPings             int64\n","getBackPings                 int64\n","holdPings                    int64\n","needVisionPings              int64\n","onMyWayPings                 int64\n","pushPings                    int64\n","retreatPings                 int64\n","visionClearedPings           int64\n","goldEarned                   int64\n","champLevel                   int64\n","champExperience              int64\n","totalMinionsKilled           int64\n","longestTimeSpentLiving       int64\n","gameEndedInSurrender         int64\n","visionScore                  int64\n","visionWardsBoughtInGame      int64\n","wardsKilled                  int64\n","wardsPlaced                  int64\n","dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>kills</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>deaths</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>assists</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>teamId</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>teamPosition</th>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th>allInPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>assistMePings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>basicPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>commandPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>dangerPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>enemyMissingPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>enemyVisionPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>getBackPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>holdPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>needVisionPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>onMyWayPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>pushPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>retreatPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>visionClearedPings</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>goldEarned</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>champLevel</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>champExperience</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>totalMinionsKilled</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>longestTimeSpentLiving</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>gameEndedInSurrender</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>visionScore</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>visionWardsBoughtInGame</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>wardsKilled</th>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>wardsPlaced</th>\n","      <td>int64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/LoL Data/exp_inputs/NA1_5176336691.parquet'\n","df = pd.read_parquet(file_path)"],"metadata":{"id":"ws_O5wI22W74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"8iTRQ_N92Ykh","outputId":"6b2ba3cb-421d-44d3-8140-9d22de3ed296"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     timestamp  feature_1  feature_2  feature_3     feature_4   feature_5  \\\n","11    108278.0       -1.0       -1.0        0.0    665.655572    5.629073   \n","14    110749.0       -1.0       -1.0        0.0    593.832286    3.381344   \n","17    125245.0       -1.0       -1.0        0.0    645.714621    6.521091   \n","20    131323.0       -1.0       -1.0        0.0    643.343394    5.317028   \n","21    136299.0       -1.0       -1.0        0.0    813.347211   10.524025   \n","..         ...        ...        ...        ...           ...         ...   \n","902  2134047.0     9257.0     6245.0        0.0  15025.302645  272.673172   \n","907  2143710.0     9371.0     7908.0        0.0  13478.230729  203.031399   \n","914  2157609.0    11603.0    11667.0        0.0  15200.836619  273.851252   \n","916  2164491.0    13052.0    12612.0        0.0  15231.074865  274.000000   \n","917  2165319.0    12867.0    12556.0       93.0  17769.650556  287.000000   \n","\n","        feature_6  feature_7  feature_8  feature_9  ...  feature_40  \\\n","11     280.000000        1.0        0.0        0.0  ...         0.0   \n","14     280.000000        0.0        0.0        0.0  ...         0.0   \n","17     280.000000        0.0        0.0        0.0  ...         0.0   \n","20     280.000000        1.0        0.0        0.0  ...         0.0   \n","21     660.000000        1.0        0.0        0.0  ...         0.0   \n","..            ...        ...        ...        ...  ...         ...   \n","902  22469.906368        0.0        1.0        0.0  ...         0.0   \n","907  15367.575977        0.0        1.0        0.0  ...         0.0   \n","914  22636.712125        0.0        0.0        1.0  ...         0.0   \n","916  22711.130343        0.0        0.0        1.0  ...         0.0   \n","917  19433.480169        0.0        1.0        0.0  ...         0.0   \n","\n","     feature_41  feature_42  feature_43  feature_44  feature_45  feature_46  \\\n","11          0.0         0.0         0.0         0.0         0.0         0.0   \n","14          0.0         0.0         0.0         0.0         0.0         0.0   \n","17          0.0         0.0         0.0         0.0         0.0         0.0   \n","20          0.0         0.0         0.0         0.0         0.0         0.0   \n","21          0.0         0.0         0.0         0.0         0.0         0.0   \n","..          ...         ...         ...         ...         ...         ...   \n","902         0.0         0.0         1.0         0.0         0.0         0.0   \n","907         1.0         0.0         0.0         0.0         0.0         0.0   \n","914         0.0         0.0         0.0         0.0         0.0         0.0   \n","916         0.0         0.0         0.0         0.0         0.0         0.0   \n","917         0.0         0.0         0.0         0.0         0.0         0.0   \n","\n","     feature_47  feature_48  feature_49  \n","11          0.0         0.0         0.0  \n","14          0.0         0.0         0.0  \n","17          0.0         0.0         0.0  \n","20          0.0         0.0         0.0  \n","21          0.0         0.0         0.0  \n","..          ...         ...         ...  \n","902         0.0         0.0         0.0  \n","907         0.0         0.0         0.0  \n","914         0.0         0.0         0.0  \n","916         0.0         0.0         0.0  \n","917         0.0         0.0         0.0  \n","\n","[264 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-ac56c530-60ca-4726-98cb-243eaaea93bb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>feature_4</th>\n","      <th>feature_5</th>\n","      <th>feature_6</th>\n","      <th>feature_7</th>\n","      <th>feature_8</th>\n","      <th>feature_9</th>\n","      <th>...</th>\n","      <th>feature_40</th>\n","      <th>feature_41</th>\n","      <th>feature_42</th>\n","      <th>feature_43</th>\n","      <th>feature_44</th>\n","      <th>feature_45</th>\n","      <th>feature_46</th>\n","      <th>feature_47</th>\n","      <th>feature_48</th>\n","      <th>feature_49</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11</th>\n","      <td>108278.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>665.655572</td>\n","      <td>5.629073</td>\n","      <td>280.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>110749.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>593.832286</td>\n","      <td>3.381344</td>\n","      <td>280.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>125245.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>645.714621</td>\n","      <td>6.521091</td>\n","      <td>280.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>131323.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>643.343394</td>\n","      <td>5.317028</td>\n","      <td>280.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>136299.0</td>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>813.347211</td>\n","      <td>10.524025</td>\n","      <td>660.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>902</th>\n","      <td>2134047.0</td>\n","      <td>9257.0</td>\n","      <td>6245.0</td>\n","      <td>0.0</td>\n","      <td>15025.302645</td>\n","      <td>272.673172</td>\n","      <td>22469.906368</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>907</th>\n","      <td>2143710.0</td>\n","      <td>9371.0</td>\n","      <td>7908.0</td>\n","      <td>0.0</td>\n","      <td>13478.230729</td>\n","      <td>203.031399</td>\n","      <td>15367.575977</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>914</th>\n","      <td>2157609.0</td>\n","      <td>11603.0</td>\n","      <td>11667.0</td>\n","      <td>0.0</td>\n","      <td>15200.836619</td>\n","      <td>273.851252</td>\n","      <td>22636.712125</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>916</th>\n","      <td>2164491.0</td>\n","      <td>13052.0</td>\n","      <td>12612.0</td>\n","      <td>0.0</td>\n","      <td>15231.074865</td>\n","      <td>274.000000</td>\n","      <td>22711.130343</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>917</th>\n","      <td>2165319.0</td>\n","      <td>12867.0</td>\n","      <td>12556.0</td>\n","      <td>93.0</td>\n","      <td>17769.650556</td>\n","      <td>287.000000</td>\n","      <td>19433.480169</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>264 rows × 50 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac56c530-60ca-4726-98cb-243eaaea93bb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ac56c530-60ca-4726-98cb-243eaaea93bb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ac56c530-60ca-4726-98cb-243eaaea93bb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bf8df418-ea13-4e4d-b6d0-62161c8c5b04\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf8df418-ea13-4e4d-b6d0-62161c8c5b04')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bf8df418-ea13-4e4d-b6d0-62161c8c5b04 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["arr1 = df.to_numpy()"],"metadata":{"id":"584WUW3CRhOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr1[:, :4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oow8AQxvr-_I","outputId":"0c95fc4d-5155-4744-900c-cf9f562fec5b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.265400e+04, -1.000000e+00, -1.000000e+00,  0.000000e+00],\n","       [ 3.628100e+04, -1.000000e+00, -1.000000e+00,  0.000000e+00],\n","       [ 3.861900e+04, -1.000000e+00, -1.000000e+00,  0.000000e+00],\n","       ...,\n","       [ 2.164056e+06, -1.000000e+00, -1.000000e+00,  0.000000e+00],\n","       [ 2.164491e+06,  1.305200e+04,  1.261200e+04,  0.000000e+00],\n","       [ 2.165319e+06,  1.286700e+04,  1.255600e+04,  9.300000e+01]])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["mins = [1,2,3,4]\n","diffs = [1,2,3,4]\n","arr1[:, :4] - mins"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9O3K5dVUriyL","outputId":"58418bf3-8dd7-4724-8b52-2ee2359d48af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.265300e+04, -3.000000e+00, -4.000000e+00, -4.000000e+00],\n","       [ 3.628000e+04, -3.000000e+00, -4.000000e+00, -4.000000e+00],\n","       [ 3.861800e+04, -3.000000e+00, -4.000000e+00, -4.000000e+00],\n","       ...,\n","       [ 2.164055e+06, -3.000000e+00, -4.000000e+00, -4.000000e+00],\n","       [ 2.164490e+06,  1.305000e+04,  1.260900e+04, -4.000000e+00],\n","       [ 2.165318e+06,  1.286500e+04,  1.255300e+04,  8.900000e+01]])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["np.stack([arr1, arr2], axis=0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcE4TykrSIEp","outputId":"e67e9450-dd1c-4ea7-aeb8-5b957daf138f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 398, 50)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["np.pad(arr1, pad_width=((0, 3), (0, 0)), mode='constant', constant_values=0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQInzX_wlFlN","outputId":"8ef34106-9b0c-46a8-a303-d2c525e4d92e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(401, 50)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## RUN THIS"],"metadata":{"id":"fWBUApkJ3cfO"}},{"cell_type":"code","source":["dfs = []\n","label_csvs = os.listdir(label_folder)\n","for label_csv in label_csvs:\n","  df = pd.read_csv(os.path.join(label_folder, label_csv))\n","  dfs.append(df)\n","label_df = pd.concat(dfs)"],"metadata":{"id":"TKVpupElh3fF","executionInfo":{"status":"ok","timestamp":1733855842915,"user_tz":300,"elapsed":4350,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["label_df[label_df['match_id'] == 'NA1_5177674379'].to_numpy()[0, 1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JX0RiqeIpxv7","outputId":"063615f6-2f50-48a6-c00c-daf667ed9323","executionInfo":{"status":"ok","timestamp":1733855848467,"user_tz":300,"elapsed":112,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([20, 20, 20, 18, 22, 20, 21, 20, 8, 20], dtype=object)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["label_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"FjBA5fl9r3ye","executionInfo":{"status":"ok","timestamp":1733802613006,"user_tz":300,"elapsed":73,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"bb10dfe5-0844-4843-f94f-d80e92bd16a2"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            match_id  summoner_1  summoner_2  summoner_3  summoner_4  \\\n","0     NA1_5177102807          30          30          30          29   \n","1     NA1_5177066754          27          29          26          28   \n","2     NA1_5177087583          29          29          28          29   \n","3     NA1_5177098367          30          29          30          29   \n","4     NA1_5177071673          29          22          30          28   \n","...              ...         ...         ...         ...         ...   \n","6013  NA1_5177201654          23          19          20          20   \n","6014  NA1_5177145970          20           5          19          20   \n","6015  NA1_5177077637          20           5          20          20   \n","6016  NA1_5172850277          19          20          20          21   \n","6017  NA1_5169829079          22          20          18          20   \n","\n","      summoner_5  summoner_6  summoner_7  summoner_8  summoner_9  summoner_10  \n","0             24          30          24          30          30           29  \n","1             27          29          29          30          29           24  \n","2             21          29          29          28          28           27  \n","3             29          29          29          27          28           30  \n","4             24          30          30          28          29           29  \n","...          ...         ...         ...         ...         ...          ...  \n","6013          20          20           5          20          19           20  \n","6014          19          23          18          20          20           21  \n","6015          20           6          20           2          20           20  \n","6016          19          20           8          20          18           21  \n","6017          21          23          20          20          19           20  \n","\n","[36413 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-fc053005-675c-4851-b245-ae550e195659\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>match_id</th>\n","      <th>summoner_1</th>\n","      <th>summoner_2</th>\n","      <th>summoner_3</th>\n","      <th>summoner_4</th>\n","      <th>summoner_5</th>\n","      <th>summoner_6</th>\n","      <th>summoner_7</th>\n","      <th>summoner_8</th>\n","      <th>summoner_9</th>\n","      <th>summoner_10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NA1_5177102807</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>29</td>\n","      <td>24</td>\n","      <td>30</td>\n","      <td>24</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NA1_5177066754</td>\n","      <td>27</td>\n","      <td>29</td>\n","      <td>26</td>\n","      <td>28</td>\n","      <td>27</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>30</td>\n","      <td>29</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NA1_5177087583</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>28</td>\n","      <td>29</td>\n","      <td>21</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>28</td>\n","      <td>28</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NA1_5177098367</td>\n","      <td>30</td>\n","      <td>29</td>\n","      <td>30</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>27</td>\n","      <td>28</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NA1_5177071673</td>\n","      <td>29</td>\n","      <td>22</td>\n","      <td>30</td>\n","      <td>28</td>\n","      <td>24</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>28</td>\n","      <td>29</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6013</th>\n","      <td>NA1_5177201654</td>\n","      <td>23</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>6014</th>\n","      <td>NA1_5177145970</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>23</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>6015</th>\n","      <td>NA1_5177077637</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>6016</th>\n","      <td>NA1_5172850277</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>21</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>6017</th>\n","      <td>NA1_5169829079</td>\n","      <td>22</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>21</td>\n","      <td>23</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>36413 rows × 11 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc053005-675c-4851-b245-ae550e195659')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc053005-675c-4851-b245-ae550e195659 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc053005-675c-4851-b245-ae550e195659');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d269a4f1-8b5d-4225-b65e-e32d5f8f9aa4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d269a4f1-8b5d-4225-b65e-e32d5f8f9aa4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d269a4f1-8b5d-4225-b65e-e32d5f8f9aa4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_3a5408ca-7d33-4324-9db2-02141db9e904\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('label_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3a5408ca-7d33-4324-9db2-02141db9e904 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('label_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"label_df","summary":"{\n  \"name\": \"label_df\",\n  \"rows\": 36413,\n  \"fields\": [\n    {\n      \"column\": \"match_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36376,\n        \"samples\": [\n          \"NA1_5167359902\",\n          \"NA1_5160005162\",\n          \"NA1_5176010614\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          9,\n          12,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          2,\n          20,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          10,\n          19,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          3,\n          16,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          2,\n          16,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          5,\n          10,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          2,\n          12,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          7,\n          12,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          5,\n          17,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": -1,\n        \"max\": 30,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          2,\n          19,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["## RUN THIS FOR FIRST TIME OR NO MATCH_IDS"],"metadata":{"id":"t0cto0-54s5h"}},{"cell_type":"code","source":["match_ids = os.listdir(input_folder)\n","match_ids = [f.split('.')[0] for f in match_ids]"],"metadata":{"id":"Sj8BoQQIqdcN","executionInfo":{"status":"ok","timestamp":1733855976566,"user_tz":300,"elapsed":116174,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["label_df[label_df['match_id'] == 'NA1_5177195624']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"hGhj7RQ6u288","executionInfo":{"status":"ok","timestamp":1733855976566,"user_tz":300,"elapsed":4,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"761a78f1-ef53-4f93-dbe2-ab105bd381cc"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            match_id  summoner_1  summoner_2  summoner_3  summoner_4  \\\n","3276  NA1_5177195624          21          20          20          20   \n","3837  NA1_5177195624          21          20          20          20   \n","\n","      summoner_5  summoner_6  summoner_7  summoner_8  summoner_9  summoner_10  \n","3276          17          20           7          20          19           20  \n","3837          17          20           7          20          19           20  "],"text/html":["\n","  <div id=\"df-1bd953f1-e808-4707-9df4-782f73efed37\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>match_id</th>\n","      <th>summoner_1</th>\n","      <th>summoner_2</th>\n","      <th>summoner_3</th>\n","      <th>summoner_4</th>\n","      <th>summoner_5</th>\n","      <th>summoner_6</th>\n","      <th>summoner_7</th>\n","      <th>summoner_8</th>\n","      <th>summoner_9</th>\n","      <th>summoner_10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3276</th>\n","      <td>NA1_5177195624</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>20</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3837</th>\n","      <td>NA1_5177195624</td>\n","      <td>21</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>20</td>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bd953f1-e808-4707-9df4-782f73efed37')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1bd953f1-e808-4707-9df4-782f73efed37 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1bd953f1-e808-4707-9df4-782f73efed37');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-03280ef2-0511-4c5c-83be-a4814b9b142c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03280ef2-0511-4c5c-83be-a4814b9b142c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-03280ef2-0511-4c5c-83be-a4814b9b142c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"label_df[label_df['match_id'] == 'NA1_5177195624']\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"match_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"NA1_5177195624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 17,\n        \"max\": 17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 19,\n        \"max\": 19,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summoner_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["def load_parquet(match_id):\n","    summary_df = pd.read_parquet(os.path.join(summary_input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\")\n","    summary_df['teamPosition'] = summary_df['teamPosition'].map(POSITION_MAP)\n","    # Check for None values\n","    if summary_df.isnull().values.any():\n","      return None\n","\n","    df = pd.read_parquet(os.path.join(input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\")\n","    df = df[(df['feature_12'] == 0) & (df['feature_13'] == 0)]\n","    length = df.to_numpy().shape[0]\n","    if length <= 0:\n","      return None\n","    try:\n","      label = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64)\n","    except:\n","      return None\n","    if -1 in label:\n","      return None\n","    return match_id\n","\n","with ThreadPoolExecutor(max_workers=10) as executor:\n","    new_match_ids = list(executor.map(load_parquet, match_ids))\n","\n","match_ids = [m for m in new_match_ids if m is not None]"],"metadata":{"id":"EGnVE4alGBaL","executionInfo":{"status":"ok","timestamp":1733859520178,"user_tz":300,"elapsed":666615,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# T_CUTOFF = 1200\n","# def load_parquet(match_id):\n","#     length = pd.read_parquet(os.path.join(input_folder, f\"{match_id}.parquet\"), engine=\"pyarrow\").to_numpy().shape[0]\n","#     if length > T_CUTOFF:\n","#       return None\n","#     label = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64)\n","#     if -1 in label:\n","#       return None\n","#     return match_id\n","\n","# with ThreadPoolExecutor() as executor:\n","#     new_match_ids = list(executor.map(load_parquet, match_ids))\n","\n","# match_ids = [m for m in new_match_ids if m is not None]"],"metadata":{"id":"ZguXCb_E6FN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(match_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpbztDmaVuIZ","outputId":"564951f8-af36-4772-932f-9b99da47400f","executionInfo":{"status":"ok","timestamp":1733859650219,"user_tz":300,"elapsed":288,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33812"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL Data/match_ids/match_ids.npy'\n","with open(save_path, 'wb') as f:\n","  np.save(f, np.array(match_ids))"],"metadata":{"id":"L0twstWafvJl","executionInfo":{"status":"ok","timestamp":1733859656182,"user_tz":300,"elapsed":175,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["## LOAD MATCH_IDS"],"metadata":{"id":"3WaBHXS04xB4"}},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL Data/match_ids/match_ids.npy'\n","with open(save_path, 'rb') as f:\n","  match_ids = np.load(f)"],"metadata":{"id":"HmrWRfosgIA2","executionInfo":{"status":"ok","timestamp":1733859743985,"user_tz":300,"elapsed":127,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["len(match_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rxPWEcCyTDn","executionInfo":{"status":"ok","timestamp":1733859744100,"user_tz":300,"elapsed":2,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"cc225299-4900-4bfe-bc89-349f04a426ff"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33812"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["### DON'T RUN NEXT CELL ONLY FOR TESTING"],"metadata":{"id":"6ZIbKiv3NOqI"}},{"cell_type":"code","source":["#### FOR TESTING PURPOSES\n","match_ids = np.random.choice(match_ids, size=100, replace=False)"],"metadata":{"id":"YRNEoDRNuN5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"D_TFoxCBYonx","executionInfo":{"status":"ok","timestamp":1733859746697,"user_tz":300,"elapsed":286,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["train_ids, val_ids = train_test_split(\n","    match_ids, test_size=0.3, random_state=42\n",")\n","\n","val_ids, test_ids = train_test_split(\n","    val_ids, test_size=0.33, random_state=42\n",")"],"metadata":{"id":"pAgsgbMgsTSf","executionInfo":{"status":"ok","timestamp":1733859746817,"user_tz":300,"elapsed":2,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["# MAX_T = 1500\n","# MAX_T = 1200\n","# MAX_T = 1000\n","MAX_T = 412\n","POSITION_MAP = {\n","    'TOP': 1,\n","    'JUNGLE': 2,\n","    'MIDDLE': 3,\n","    'BOTTOM': 4,\n","    'UTILITY': 5,\n","}\n","ping_cols = ['allInPings',\n"," 'assistMePings',\n"," 'basicPings',\n"," 'commandPings',\n"," 'dangerPings',\n"," 'enemyMissingPings',\n"," 'enemyVisionPings',\n"," 'getBackPings',\n"," 'holdPings',\n"," 'needVisionPings',\n"," 'onMyWayPings',\n"," 'pushPings',\n"," 'retreatPings',\n"," 'visionClearedPings']\n","\n","summary_normalizing_cols = ['kills', 'deaths', 'assists', 'goldEarned', 'champExperience', 'totalMinionsKilled', 'longestTimeSpentLiving', 'visionScore', 'visionWardsBoughtInGame', 'wardsKilled', 'wardsPlaced', 'totalPings']\n","\n","# len 8 numpy array\n","input_data_mins = np.array(\n","    [3.42520000e+04, -1.00000000e+00, -1.00000000e+00, 0.00000000e+00, 5.00573990e+02, 0.00000000e+00, 6.51923942e-02, 0.00000000e+00]\n",")\n","input_data_maxes = np.array(\n","    [4.02087200e+06, 1.46400000e+04, 1.47060000e+04, 8.00000000e+02, 3.74424520e+04, 6.42440200e+02, 5.07452965e+04, 1.00000000e+00]\n",")\n","\n","# numpy array\n","summary_input_mins = np.array(\n","    [11, 12, 14, 16530, 22541, 96, 708, 30, 3, 4, 12, 51]\n",")\n","summary_input_maxes = np.array(\n","    [39, 31, 40, 30052, 39838, 541, 2901, 229, 31, 44, 194, 334]\n",")\n","\n","class LoLDataset(Dataset):\n","    def __init__(self, match_ids):\n","      self.match_ids = match_ids\n","      # self.max_T = max_T\n","\n","    def __len__(self):\n","      return len(self.match_ids)\n","\n","    def __getitem__(self, idx):\n","      datapoint = self._load_data(self.match_ids[idx])\n","      return datapoint\n","\n","    def _load_data(self, match_id):\n","      input_file = os.path.join(input_folder, f\"{match_id}.parquet\")\n","      summary_input_file = os.path.join(summary_input_folder, f\"{match_id}.parquet\")\n","\n","      input_data = pd.read_parquet(input_file, engine=\"pyarrow\")\n","      input_data = input_data[(input_data['feature_12'] == 0) & (input_data['feature_13'] == 0)].to_numpy() # ignore ward events\n","      input_data[:, 1:8] = (input_data[:, 1:8] - input_data_mins[1:]) / (input_data_maxes[1:] - input_data_mins[1:]) # FOR NOW IGNORE TIMESTAMP NORMALIZATION FOR EMBEDDING PURPOSES\n","      if input_data.shape[0] > MAX_T:\n","        print('HELLO HELLO HELLO')\n","        raise Exception(\"loading match with greater than 1500 events\")\n","      input_data = np.pad(input_data, pad_width=((0, MAX_T - input_data.shape[0]), (0, 0)), mode='constant', constant_values=0).astype(np.float32) # (max_T, 50)\n","\n","      summary_input_data = pd.read_parquet(summary_input_file, engine=\"pyarrow\")\n","      summary_input_data['teamPosition'] = summary_input_data['teamPosition'].map(POSITION_MAP)\n","      summary_input_data['gameEndedInSurrender'] = summary_input_data['gameEndedInSurrender'].astype(int)\n","      summary_input_data['totalPings'] = summary_input_data[ping_cols].sum(axis=1)\n","      summary_input_data.drop(ping_cols, axis=1, inplace=True)\n","\n","      summary_input_data[summary_normalizing_cols] = (summary_input_data[summary_normalizing_cols] - summary_input_mins) / (summary_input_maxes - summary_input_mins)\n","      summary_input_data = summary_input_data.to_numpy().astype(np.float32)\n","\n","      # NORMALIZE DATA\n","      # (10, 16)\n","\n","      labels = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64) # (10,)\n","\n","      # print(input_data.shape)\n","      # print(summary_input_data.shape)\n","      # print(labels.shape)\n","\n","      return {'input_data': input_data, 'summary_input_data': summary_input_data, 'labels': labels}"],"metadata":{"id":"HlzV52e6YNHq","executionInfo":{"status":"ok","timestamp":1733859747559,"user_tz":300,"elapsed":168,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["train_dataset = LoLDataset(train_ids)\n","val_dataset = LoLDataset(val_ids)\n","test_dataset = LoLDataset(test_ids)"],"metadata":{"id":"Thv-3psKrgk8","executionInfo":{"status":"ok","timestamp":1733859749781,"user_tz":300,"elapsed":144,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","N_WORKERS = 2\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS, pin_memory=True)"],"metadata":{"id":"bwWX3D_lrgpF","executionInfo":{"status":"ok","timestamp":1733859752224,"user_tz":300,"elapsed":128,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]['summary_input_data']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdxtQPq2A3a6","executionInfo":{"status":"ok","timestamp":1733858441531,"user_tz":300,"elapsed":104,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"9ea4a5c8-8df1-4679-818e-80688a554650"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.50000000e-01, -1.57894731e-01, -4.61538464e-01,\n","         1.00000000e+02,  1.00000000e+00, -4.49045986e-01,\n","         1.40000000e+01, -6.31323338e-01,  2.22471908e-01,\n","        -1.93798453e-01,  0.00000000e+00, -8.04020092e-02,\n","        -1.07142858e-01, -7.50000030e-02, -2.74725277e-02,\n","        -2.47349832e-02],\n","       [-2.85714298e-01, -2.63157904e-01, -2.30769232e-01,\n","         1.00000000e+02,  2.00000000e+00, -5.22260010e-01,\n","         1.40000000e+01, -6.41556323e-01, -1.55056179e-01,\n","         1.82398537e-03,  0.00000000e+00, -6.03015088e-02,\n","        -1.07142858e-01, -5.00000007e-02, -1.09890113e-02,\n","         0.00000000e+00],\n","       [-1.42857149e-01, -1.57894731e-01, -3.07692319e-01,\n","         1.00000000e+02,  3.00000000e+00, -1.86141104e-01,\n","         1.60000000e+01, -4.47360814e-01,  2.47191012e-01,\n","        -1.09439127e-01,  0.00000000e+00, -6.53266311e-02,\n","        -3.57142873e-02, -1.00000001e-01,  0.00000000e+00,\n","        -9.18727890e-02],\n","       [-3.57142873e-02, -2.10526317e-01, -4.23076928e-01,\n","         1.00000000e+02,  4.00000000e+00, -2.14021593e-01,\n","         1.50000000e+01, -5.11244714e-01,  3.19101125e-01,\n","        -1.25398993e-01,  0.00000000e+00, -9.54773873e-02,\n","        -7.14285746e-02, -1.00000001e-01, -1.64835174e-02,\n","        -9.89399329e-02],\n","       [-3.92857134e-01, -1.05263159e-01, -1.53846160e-01,\n","         1.00000000e+02,  5.00000000e+00, -6.78745747e-01,\n","         1.30000000e+01, -6.52540922e-01, -1.12359554e-01,\n","        -1.74646601e-01,  0.00000000e+00,  6.53266311e-02,\n","         3.57142873e-02,  7.50000030e-02,  2.74725277e-02,\n","        -6.36042431e-02],\n","       [-2.14285716e-01, -3.15789461e-01, -3.46153855e-01,\n","         2.00000000e+02,  1.00000000e+00, -1.92796931e-01,\n","         1.70000000e+01, -3.18783611e-01,  2.71910101e-01,\n","        -1.23119012e-01,  0.00000000e+00, -8.04020092e-02,\n","        -1.07142858e-01, -7.50000030e-02, -2.19780225e-02,\n","         3.53356898e-02],\n","       [-1.42857149e-01, -4.21052635e-01,  1.53846160e-01,\n","         2.00000000e+02,  2.00000000e+00, -1.03830792e-01,\n","         1.70000000e+01, -3.05255234e-01, -1.25842690e-01,\n","        -1.35430917e-01,  0.00000000e+00, -6.53266311e-02,\n","        -1.07142858e-01, -5.00000007e-02, -5.49450554e-02,\n","        -1.16607770e-01],\n","       [-3.57142873e-02, -5.26315808e-01, -1.53846160e-01,\n","         2.00000000e+02,  3.00000000e+00, -1.19952671e-01,\n","         1.70000000e+01, -2.71434367e-01,  3.03370774e-01,\n","         2.52621979e-01,  0.00000000e+00, -7.03517571e-02,\n","        -7.14285746e-02, -7.50000030e-02, -1.64835174e-02,\n","         1.20141342e-01],\n","       [-7.14285746e-02, -3.68421048e-01, -1.92307696e-01,\n","         2.00000000e+02,  4.00000000e+00, -1.74012721e-01,\n","         1.60000000e+01, -4.21691626e-01,  2.58426964e-01,\n","         2.69037839e-02,  0.00000000e+00, -5.02512567e-02,\n","        -1.07142858e-01,  0.00000000e+00, -1.64835174e-02,\n","        -7.06713796e-02],\n","       [ 3.57142873e-02, -2.63157904e-01, -1.92307696e-01,\n","         2.00000000e+02,  5.00000000e+00, -4.59621370e-01,\n","         1.40000000e+01, -6.35948420e-01, -1.23595506e-01,\n","        -1.32694945e-01,  0.00000000e+00,  3.01507533e-01,\n","        -3.57142873e-02,  2.24999994e-01,  1.37362644e-01,\n","        -1.30742043e-01]], dtype=float32)"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"n7oxnr-mDWBP"}},{"cell_type":"code","source":["import gc"],"metadata":{"id":"CfoOB6LeyK1K","executionInfo":{"status":"ok","timestamp":1733806321394,"user_tz":300,"elapsed":94,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["# set up the model and optimizer\n","\n","import torch.optim as optim\n","\n","max_T = MAX_T\n","dim = 50\n","attn_dim = 128\n","mlp_dim = 256\n","summary_dim = 16\n","num_classes = 31\n","hidden_dim = 10\n","\n","# no_embedding = ShepADoodle(emb_type='none', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# sin_embedding = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","model = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, hidden_dim=hidden_dim, summary_dim=summary_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6, num_classes=num_classes).cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","NUM_EPOCHS = 15\n","optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"],"metadata":{"id":"XrBPScd5DWqv","executionInfo":{"status":"ok","timestamp":1733859758523,"user_tz":300,"elapsed":132,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["model_name = \"sin\""],"metadata":{"id":"cbdlPHZ61V8Q","executionInfo":{"status":"ok","timestamp":1733859772551,"user_tz":300,"elapsed":266,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["# Training\n","import tqdm\n","\n","train_losses = []\n","val_losses = []\n","for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n","    loss_meter = AverageMeter()\n","    # train_batch_losses = []\n","    for datapoint in tqdm.tqdm(train_dataloader):\n","        # torch.cuda.empty_cache()\n","        # get the inputs;\n","        inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","        # print(raw_inputs.shape)\n","\n","        # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","        if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","          inputs[:, :, 0] = inputs[:, :, 0] / 4.02087200e+06\n","\n","        inputs = inputs.cuda()\n","        summary_inputs = summary_inputs.cuda()\n","        labels = labels.cuda()\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","        # Check for NaNs\n","        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n","            print(\"NaN or Inf detected in model output\")\n","            break\n","\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","        loss_meter.update(loss.item(), inputs.shape[0])\n","        # with torch.cuda.stream(stream_ma|in):\n","        # train_batch_losses.append(loss.item())\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    scheduler.step()\n","    # val_batch_losses = []\n","    val_meter = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","      for datapoint in tqdm.tqdm(val_dataloader):\n","          # torch.cuda.empty_cache()\n","          inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","          # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","          if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","            inputs[:, :, 0] = inputs[:, :, 0] / (4.02087200e+06)\n","\n","          inputs = inputs.cuda()\n","          summary_inputs = summary_inputs.cuda()\n","          labels = labels.cuda()\n","\n","          outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","          loss = criterion(outputs, labels)\n","          val_meter.update(loss.item(), inputs.shape[0])\n","        # with to?rch.cuda.stream(stream_main):\n","        # val_batch_losses.append(loss.item())\n","\n","    # torch.cuda.synchronize()\n","    # val_loss = np.mean(val_batch_losses)\n","\n","    # train_losses.append(train_loss)\n","    # val_losses.append(val_loss)\n","    # print(f\"Train Epoch: {epoch}, Training Loss: {train_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    # print(f\"Train Epoch: {epoch}, Validation Loss: {val_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    train_losses.append(loss_meter.calculate())\n","    val_losses.append(val_meter.calculate())\n","    print(f\"Train Epoch: {epoch}, Training Loss: {loss_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    print(f\"Train Epoch: {epoch}, Validation Loss: {val_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_epoch_{epoch}.pt'\n","    torch.save(model.state_dict(), save_path)\n","\n","    model.train()\n"],"metadata":{"id":"Y5gRZDvqF_AH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a634711a-d946-40db-dcc7-35d645ce4430","executionInfo":{"status":"ok","timestamp":1733865381701,"user_tz":300,"elapsed":5609152,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":82,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:49<00:00,  2.55it/s]\n","100%|██████████| 213/213 [01:20<00:00,  2.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 0, Training Loss: 5.3651, LR: 9.890738003669029e-06\n","Train Epoch: 0, Validation Loss: 4.0967, LR: 9.890738003669029e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:46<00:00,  2.58it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1, Training Loss: 3.7127, LR: 9.567727288213005e-06\n","Train Epoch: 1, Validation Loss: 3.5066, LR: 9.567727288213005e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:48<00:00,  2.57it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 2, Training Loss: 3.4683, LR: 9.045084971874738e-06\n","Train Epoch: 2, Validation Loss: 3.4486, LR: 9.045084971874738e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:48<00:00,  2.56it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 3, Training Loss: 3.4456, LR: 8.345653031794292e-06\n","Train Epoch: 3, Validation Loss: 3.4411, LR: 8.345653031794292e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:48<00:00,  2.57it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 4, Training Loss: 3.4410, LR: 7.5e-06\n","Train Epoch: 4, Validation Loss: 3.4382, LR: 7.5e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:13<00:00,  2.36it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 5, Training Loss: 3.4383, LR: 6.545084971874738e-06\n","Train Epoch: 5, Validation Loss: 3.4355, LR: 6.545084971874738e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:50<00:00,  2.55it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 6, Training Loss: 3.4359, LR: 5.522642316338269e-06\n","Train Epoch: 6, Validation Loss: 3.4332, LR: 5.522642316338269e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:52<00:00,  2.53it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 7, Training Loss: 3.4339, LR: 4.477357683661735e-06\n","Train Epoch: 7, Validation Loss: 3.4316, LR: 4.477357683661735e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:50<00:00,  2.55it/s]\n","100%|██████████| 213/213 [01:23<00:00,  2.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 8, Training Loss: 3.4322, LR: 3.4549150281252644e-06\n","Train Epoch: 8, Validation Loss: 3.4300, LR: 3.4549150281252644e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:57<00:00,  2.48it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 9, Training Loss: 3.4307, LR: 2.500000000000002e-06\n","Train Epoch: 9, Validation Loss: 3.4289, LR: 2.500000000000002e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:49<00:00,  2.56it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 10, Training Loss: 3.4296, LR: 1.654346968205711e-06\n","Train Epoch: 10, Validation Loss: 3.4278, LR: 1.654346968205711e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:50<00:00,  2.55it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 11, Training Loss: 3.4288, LR: 9.549150281252635e-07\n","Train Epoch: 11, Validation Loss: 3.4272, LR: 9.549150281252635e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:50<00:00,  2.55it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 12, Training Loss: 3.4283, LR: 4.3227271178699523e-07\n","Train Epoch: 12, Validation Loss: 3.4269, LR: 4.3227271178699523e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:51<00:00,  2.54it/s]\n","100%|██████████| 213/213 [01:22<00:00,  2.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 13, Training Loss: 3.4280, LR: 1.092619963309716e-07\n","Train Epoch: 13, Validation Loss: 3.4267, LR: 1.092619963309716e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:48<00:00,  2.56it/s]\n","100%|██████████| 213/213 [01:21<00:00,  2.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 14, Training Loss: 3.4278, LR: 0.0\n","Train Epoch: 14, Validation Loss: 3.4266, LR: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["model_name = \"sin\"\n","save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_final.pt'\n","torch.save(model.state_dict(), save_path)"],"metadata":{"id":"92xoDWWAgBWC","executionInfo":{"status":"ok","timestamp":1733865382013,"user_tz":300,"elapsed":162,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["test_meter = AverageMeter()\n","for datapoint in tqdm.tqdm(test_dataloader):\n","  inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","  # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","  if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","    inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","  inputs = inputs.cuda()\n","  summary_inputs = summary_inputs.cuda()\n","  labels = labels.cuda()\n","\n","  outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","  loss = criterion(outputs, labels)\n","  test_meter.update(loss.item(), inputs.shape[0])\n","\n","test_loss = test_meter.calculate()\n","print(f\"Test Loss: {test_meter.calculate():0.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5ku8AiK9kWI","outputId":"7e4c7334-cbba-4dc2-8f1c-8474d3b876a7","executionInfo":{"status":"ok","timestamp":1733871478417,"user_tz":300,"elapsed":43624,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":86,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 105/105 [00:43<00:00,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 3.4285\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/train_losses.npy'\n","np.save(save_path, np.array(train_losses))"],"metadata":{"id":"8FwAzrgEQBf5","executionInfo":{"status":"ok","timestamp":1733871478417,"user_tz":300,"elapsed":9,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/val_losses.npy'\n","np.save(save_path, np.array(val_losses))"],"metadata":{"id":"RHWF0P3OQFFy","executionInfo":{"status":"ok","timestamp":1733871478417,"user_tz":300,"elapsed":9,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["class LoLDataset8(Dataset):\n","    def __init__(self, match_ids):\n","      self.match_ids = match_ids\n","      # self.max_T = max_T\n","\n","    def __len__(self):\n","      return len(self.match_ids)\n","\n","    def __getitem__(self, idx):\n","      datapoint = self._load_data(self.match_ids[idx])\n","      return datapoint\n","\n","    def _load_data(self, match_id):\n","      input_file = os.path.join(input_folder, f\"{match_id}.parquet\")\n","      summary_input_file = os.path.join(summary_input_folder, f\"{match_id}.parquet\")\n","\n","      input_data = pd.read_parquet(input_file, engine=\"pyarrow\")\n","      input_data = input_data[(input_data['feature_12'] == 0) & (input_data['feature_13'] == 0)].to_numpy() # ignore ward events\n","      input_data[:, 1:8] = (input_data[:, 1:8] - input_data_mins[1:]) / (input_data_maxes[1:] - input_data_mins[1:]) # FOR NOW IGNORE TIMESTAMP NORMALIZATION FOR EMBEDDING PURPOSES\n","      if input_data.shape[0] > MAX_T:\n","        print('HELLO HELLO HELLO')\n","        raise Exception(\"loading match with greater than 1500 events\")\n","      input_data = np.pad(input_data, pad_width=((0, MAX_T - input_data.shape[0]), (0, 0)), mode='constant', constant_values=0).astype(np.float32) # (max_T, 50)\n","\n","      summary_input_data = pd.read_parquet(summary_input_file, engine=\"pyarrow\")\n","      summary_input_data['teamPosition'] = summary_input_data['teamPosition'].map(POSITION_MAP)\n","      summary_input_data['gameEndedInSurrender'] = summary_input_data['gameEndedInSurrender'].astype(int)\n","      summary_input_data['totalPings'] = summary_input_data[ping_cols].sum(axis=1)\n","      summary_input_data.drop(ping_cols, axis=1, inplace=True)\n","\n","      summary_input_data[summary_normalizing_cols] = (summary_input_data[summary_normalizing_cols] - summary_input_mins) / (summary_input_maxes - summary_input_mins)\n","      summary_input_data = summary_input_data.to_numpy().astype(np.float32)\n","\n","      # NORMALIZE DATA\n","      # (10, 16)\n","\n","      labels = label_df[label_df['match_id'] == match_id].to_numpy()[0, 1:].astype(np.int64) # (10,)\n","      labels = np.floor(labels / 4).astype(np.int64)\n","\n","      # print(input_data.shape)\n","      # print(summary_input_data.shape)\n","      # print(labels.shape)\n","\n","      return {'input_data': input_data, 'summary_input_data': summary_input_data, 'labels': labels}\n","\n","train_dataset8 = LoLDataset8(train_ids)\n","val_dataset8 = LoLDataset8(val_ids)\n","test_dataset8 = LoLDataset8(test_ids)\n","\n","BATCH_SIZE = 32\n","N_WORKERS = 2\n","train_dataloader8 = DataLoader(train_dataset8, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","val_dataloader8 = DataLoader(val_dataset8, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n","test_dataloader8 = DataLoader(test_dataset8, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS, pin_memory=True)"],"metadata":{"id":"m0_pWkBASg4E","executionInfo":{"status":"ok","timestamp":1733871478417,"user_tz":300,"elapsed":9,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","max_T = MAX_T\n","dim = 50\n","attn_dim = 128\n","mlp_dim = 256\n","summary_dim = 16\n","# PREDICT ONLY RANK INSTEAD\n","num_classes = 8\n","hidden_dim = 10\n","\n","# no_embedding = ShepADoodle(emb_type='none', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# abs_embedding = ShepADoodle(emb_type='abs_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# sin_embedding = ShepADoodle(emb_type='sin', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","# rel_embedding = ShepADoodle(emb_type='rel_nn', max_T=max_T, dim=dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6).cuda()\n","model = ShepADoodle(emb_type='abs', max_T=max_T, dim=dim, hidden_dim=hidden_dim, summary_dim=summary_dim, attn_dim=attn_dim, mlp_dim=mlp_dim, num_heads=8, num_layers=6, num_classes=num_classes).cuda()\n","model_name = \"abs\"\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","NUM_EPOCHS = 15\n","optimizer = optim.AdamW(model.parameters(), lr=0.00001)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)"],"metadata":{"id":"qYEv3s6lIzBu","executionInfo":{"status":"ok","timestamp":1733884091298,"user_tz":300,"elapsed":315,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["# Training\n","import tqdm\n","\n","train_losses = []\n","val_losses = []\n","for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n","    loss_meter = AverageMeter()\n","    # train_batch_losses = []\n","    for datapoint in tqdm.tqdm(train_dataloader8):\n","        # get the inputs;\n","        inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","        # print(raw_inputs.shape)\n","\n","        # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","        if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","          inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","        inputs = inputs.cuda()\n","        summary_inputs = summary_inputs.cuda()\n","        labels = labels.cuda()\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # print(inputs.shape)\n","        # print(summary_inputs.shape)\n","\n","        # forward + backward + optimize\n","        outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","        loss_meter.update(loss.item(), inputs.shape[0])\n","        # with torch.cuda.stream(stream_main):\n","        # train_batch_losses.append(loss.item())\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    scheduler.step()\n","\n","    # val_batch_losses = []\n","    val_meter = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","      for datapoint in tqdm.tqdm(val_dataloader8):\n","          # torch.cuda.empty_cache()\n","          inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","          # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","          if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","            inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","          inputs = inputs.cuda()\n","          summary_inputs = summary_inputs.cuda()\n","          labels = labels.cuda()\n","\n","          outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","          loss = criterion(outputs, labels)\n","          val_meter.update(loss.item(), inputs.shape[0])\n","        # with to?rch.cuda.stream(stream_main):\n","        # val_batch_losses.append(loss.item())\n","\n","    # torch.cuda.synchronize()\n","    # val_loss = np.mean(val_batch_losses)\n","\n","    # train_losses.append(train_loss)\n","    # val_losses.append(val_loss)\n","    # print(f\"Train Epoch: {epoch}, Training Loss: {train_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    # print(f\"Train Epoch: {epoch}, Validation Loss: {val_loss:0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    train_losses.append(loss_meter.calculate())\n","    val_losses.append(val_meter.calculate())\n","    print(f\"Train Epoch: {epoch}, Training Loss: {loss_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","    print(f\"Train Epoch: {epoch}, Validation Loss: {val_meter.calculate():0.4f}, LR: {scheduler.get_last_lr()[0]}\")\n","\n","    save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_epoch_{epoch}.pt'\n","    torch.save(model.state_dict(), save_path)\n","\n","    model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvGUx-yw5o6N","executionInfo":{"status":"ok","timestamp":1733889913455,"user_tz":300,"elapsed":5816509,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"d730881c-a7ee-48e6-ef80-6f655d86be75"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [04:58<00:00,  2.48it/s]\n","100%|██████████| 213/213 [01:24<00:00,  2.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 0, Training Loss: 3.0092, LR: 9.890738003669029e-06\n","Train Epoch: 0, Validation Loss: 2.3623, LR: 9.890738003669029e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:02<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:27<00:00,  2.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1, Training Loss: 2.1796, LR: 9.567727288213005e-06\n","Train Epoch: 1, Validation Loss: 2.0997, LR: 9.567727288213005e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:03<00:00,  2.44it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 2, Training Loss: 2.0910, LR: 9.045084971874738e-06\n","Train Epoch: 2, Validation Loss: 2.0869, LR: 9.045084971874738e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:00<00:00,  2.46it/s]\n","100%|██████████| 213/213 [01:26<00:00,  2.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 3, Training Loss: 2.0846, LR: 8.345653031794292e-06\n","Train Epoch: 3, Validation Loss: 2.0834, LR: 8.345653031794292e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:00<00:00,  2.46it/s]\n","100%|██████████| 213/213 [01:26<00:00,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 4, Training Loss: 2.0811, LR: 7.5e-06\n","Train Epoch: 4, Validation Loss: 2.0795, LR: 7.5e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:02<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:26<00:00,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 5, Training Loss: 2.0778, LR: 6.545084971874738e-06\n","Train Epoch: 5, Validation Loss: 2.0778, LR: 6.545084971874738e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:02<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 6, Training Loss: 2.0750, LR: 5.522642316338269e-06\n","Train Epoch: 6, Validation Loss: 2.0747, LR: 5.522642316338269e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:01<00:00,  2.46it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 7, Training Loss: 2.0721, LR: 4.477357683661735e-06\n","Train Epoch: 7, Validation Loss: 2.0709, LR: 4.477357683661735e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:03<00:00,  2.44it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 8, Training Loss: 2.0697, LR: 3.4549150281252644e-06\n","Train Epoch: 8, Validation Loss: 2.0691, LR: 3.4549150281252644e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:01<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 9, Training Loss: 2.0676, LR: 2.500000000000002e-06\n","Train Epoch: 9, Validation Loss: 2.0670, LR: 2.500000000000002e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:01<00:00,  2.46it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 10, Training Loss: 2.0659, LR: 1.654346968205711e-06\n","Train Epoch: 10, Validation Loss: 2.0658, LR: 1.654346968205711e-06\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:03<00:00,  2.44it/s]\n","100%|██████████| 213/213 [01:26<00:00,  2.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 11, Training Loss: 2.0645, LR: 9.549150281252635e-07\n","Train Epoch: 11, Validation Loss: 2.0652, LR: 9.549150281252635e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:00<00:00,  2.46it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 12, Training Loss: 2.0637, LR: 4.3227271178699523e-07\n","Train Epoch: 12, Validation Loss: 2.0641, LR: 4.3227271178699523e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:01<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:25<00:00,  2.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 13, Training Loss: 2.0632, LR: 1.092619963309716e-07\n","Train Epoch: 13, Validation Loss: 2.0638, LR: 1.092619963309716e-07\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 740/740 [05:01<00:00,  2.45it/s]\n","100%|██████████| 213/213 [01:28<00:00,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 14, Training Loss: 2.0630, LR: 0.0\n","Train Epoch: 14, Validation Loss: 2.0637, LR: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/params_final.pt'\n","torch.save(model.state_dict(), save_path)"],"metadata":{"id":"9IDfVVAl7R9z","executionInfo":{"status":"ok","timestamp":1733890178983,"user_tz":300,"elapsed":160,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["test_meter = AverageMeter()\n","for datapoint in tqdm.tqdm(test_dataloader8):\n","  inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","\n","  # NORMALIZE TIMESTAMP IF NOT USED FOR EMBEDDING\n","  if model.emb_type == 'none' or model.emb_type == 'sin' or model.emb_type == 'abs_nn' or model.emb_type == 'rel_nn':\n","    inputs[:, :, 0] = (inputs[:, :, 0] - 3.42520000e+04) / (4.02087200e+06 - 3.74424520e+04)\n","\n","  inputs = inputs.cuda()\n","  summary_inputs = summary_inputs.cuda()\n","  labels = labels.cuda()\n","\n","  outputs, _ = model(inputs=inputs, summary_inputs=summary_inputs)\n","\n","  loss = criterion(outputs, labels)\n","  test_meter.update(loss.item(), inputs.shape[0])\n","\n","test_loss = test_meter.calculate()\n","print(f\"Test Loss: {test_meter.calculate():0.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkup-Xg_8OHj","executionInfo":{"status":"ok","timestamp":1733890226436,"user_tz":300,"elapsed":43183,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"83ed7a7b-70fd-49f4-e0d1-d9af053c0f11"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 105/105 [00:43<00:00,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 2.0638\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/train_losses.npy'\n","np.save(save_path, np.array(train_losses))"],"metadata":{"id":"V3AQ4vZxANsE","executionInfo":{"status":"ok","timestamp":1733890226436,"user_tz":300,"elapsed":8,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["save_path = f'/content/drive/My Drive/LoL_models/{model_name}/val_losses.npy'\n","np.save(save_path, np.array(val_losses))"],"metadata":{"id":"vDApfYLD8jlt","executionInfo":{"status":"ok","timestamp":1733890226436,"user_tz":300,"elapsed":8,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","with torch.no_grad():\n","  for datapoint in tqdm.tqdm(test_dataloader):\n","    inputs, summary_inputs, labels = datapoint['input_data'], datapoint['summary_input_data'], datapoint['labels']\n","    outputs, _ = model(inputs=inputs.cuda(), summary_inputs=summary_inputs.cuda())\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"9QjOxMkvDdsG","executionInfo":{"status":"error","timestamp":1733892817926,"user_tz":300,"elapsed":1915,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"1a62c2e9-3910-489e-bf2e-ffa192ebf270"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/105 [00:01<?, ?it/s]\n"]},{"output_type":"error","ename":"IndexError","evalue":"too many indices for tensor of dimension 2","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-128-3e973a41e53c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdatapoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_input_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-110-f6c204fef623>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, summary_inputs, return_attn)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Embed/Reduce dimensionality of input before passing it into positional embedder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m       \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0memb_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"cell_type":"code","source":["torch.max(nn.functional.softmax(outputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so754ki-ECIK","executionInfo":{"status":"ok","timestamp":1733892893909,"user_tz":300,"elapsed":110,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"23f6717b-8c48-4d26-9b16-acd411139d2e"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-135-292ec955c5c3>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  torch.max(nn.functional.softmax(outputs))\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.0447, device='cuda:0')"]},"metadata":{},"execution_count":135}]},{"cell_type":"markdown","source":["# Testing stuff"],"metadata":{"id":"GRcdLqtXPuwu"}},{"cell_type":"code","source":["# import gc\n","# import torch\n","\n","# List all tensors\n","for obj in gc.get_objects():\n","    if torch.is_tensor(obj):\n","        print(f\"Tensor: {obj.shape}, dtype: {obj.dtype}, device: {obj.device}, size: {obj.element_size() * obj.nelement() / 1e6}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rk3JVmXIaGJ","outputId":"8708ca7d-57e3-484e-cd8f-110ea2ddcd98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor: torch.Size([16, 310]), dtype: torch.float32, device: cuda:0, size: 0.01984\n","Tensor: torch.Size([16, 31, 10]), dtype: torch.float32, device: cuda:0, size: 0.01984\n","Tensor: torch.Size([]), dtype: torch.float32, device: cuda:0, size: 4e-06\n","Tensor: torch.Size([]), dtype: torch.float32, device: cuda:0, size: 4e-06\n","Tensor: torch.Size([64, 1]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 64]), dtype: torch.float32, device: cuda:0, size: 0.016384\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 1]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 64]), dtype: torch.float32, device: cuda:0, size: 0.016384\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([310]), dtype: torch.float32, device: cuda:0, size: 0.00124\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([310, 339]), dtype: torch.float32, device: cuda:0, size: 0.42036\n","Tensor: torch.Size([290]), dtype: torch.float32, device: cuda:0, size: 0.00116\n","Tensor: torch.Size([290]), dtype: torch.float32, device: cuda:0, size: 0.00116\n","Tensor: torch.Size([128, 290]), dtype: torch.float32, device: cuda:0, size: 0.14848\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([290, 128]), dtype: torch.float32, device: cuda:0, size: 0.14848\n","Tensor: torch.Size([290]), dtype: torch.float32, device: cuda:0, size: 0.00116\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49, 512]), dtype: torch.float32, device: cuda:0, size: 0.100352\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([128, 49]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([128]), dtype: torch.float32, device: cuda:0, size: 0.000512\n","Tensor: torch.Size([49, 128]), dtype: torch.float32, device: cuda:0, size: 0.025088\n","Tensor: torch.Size([49]), dtype: torch.float32, device: cuda:0, size: 0.000196\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([64, 49]), dtype: torch.float32, device: cuda:0, size: 0.012544\n","Tensor: torch.Size([64]), dtype: torch.float32, device: cuda:0, size: 0.000256\n","Tensor: torch.Size([16, 1200, 50]), dtype: torch.float32, device: cpu, size: 3.84\n","Tensor: torch.Size([16, 10, 29]), dtype: torch.float32, device: cpu, size: 0.01856\n","Tensor: torch.Size([16, 10]), dtype: torch.int64, device: cpu, size: 0.00128\n","Tensor: torch.Size([16, 1200, 50]), dtype: torch.float32, device: cuda:0, size: 3.84\n","Tensor: torch.Size([16, 10, 29]), dtype: torch.float32, device: cuda:0, size: 0.01856\n","Tensor: torch.Size([16, 10]), dtype: torch.int64, device: cuda:0, size: 0.00128\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 5898.24\n","Tensor: torch.Size([16, 1200, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 5898.24\n","Tensor: torch.Size([16, 1200, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 5898.24\n","Tensor: torch.Size([16, 1200, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 5898.24\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 64]), dtype: torch.float32, device: cuda:0, size: 4.9152\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 512]), dtype: torch.float32, device: cuda:0, size: 39.3216\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 512]), dtype: torch.float32, device: cuda:0, size: 39.3216\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 512]), dtype: torch.float32, device: cuda:0, size: 39.3216\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 512]), dtype: torch.float32, device: cuda:0, size: 39.3216\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 512]), dtype: torch.float32, device: cuda:0, size: 39.3216\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 128]), dtype: torch.float32, device: cuda:0, size: 9.8304\n","Tensor: torch.Size([16, 1200, 49]), dtype: torch.float32, device: cuda:0, size: 3.7632\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n","Tensor: torch.Size([16, 1200, 1200]), dtype: torch.float32, device: cuda:0, size: 92.16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n","  return isinstance(obj, torch.Tensor)\n"]}]},{"cell_type":"code","source":["# model = Net()\n","for name, param in model.named_parameters():\n","    print(name, param.size(), param.element_size() * param.nelement() / 1e6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AB-sE-DJbDT","outputId":"5d15a347-fe25-41bb-9d89-755e8d0e02df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pos_E.rel_K.weight torch.Size([101, 128]) 0.051712\n","pos_E.rel_V.weight torch.Size([101, 128]) 0.051712\n","transformer.layers.0.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.0.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.0.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.0.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.0.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.0.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.0.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.0.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.0.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.0.ffn.net.3.bias torch.Size([49]) 0.000196\n","transformer.layers.1.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.1.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.1.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.1.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.1.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.1.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.1.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.1.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.1.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.1.ffn.net.3.bias torch.Size([49]) 0.000196\n","transformer.layers.2.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.2.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.2.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.2.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.2.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.2.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.2.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.2.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.2.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.2.ffn.net.3.bias torch.Size([49]) 0.000196\n","transformer.layers.3.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.3.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.3.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.3.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.3.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.3.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.3.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.3.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.3.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.3.ffn.net.3.bias torch.Size([49]) 0.000196\n","transformer.layers.4.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.4.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.4.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.4.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.4.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.4.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.4.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.4.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.4.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.4.ffn.net.3.bias torch.Size([49]) 0.000196\n","transformer.layers.5.attn.attn_heads.0.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.0.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.0.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.0.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.0.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.0.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.1.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.1.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.1.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.1.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.1.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.1.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.2.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.2.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.2.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.2.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.2.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.2.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.3.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.3.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.3.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.3.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.3.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.3.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.4.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.4.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.4.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.4.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.4.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.4.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.5.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.5.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.5.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.5.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.5.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.5.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.6.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.6.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.6.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.6.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.6.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.6.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.7.W_K.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.7.W_K.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.7.W_Q.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.7.W_Q.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.attn_heads.7.W_V.weight torch.Size([128, 49]) 0.025088\n","transformer.layers.5.attn.attn_heads.7.W_V.bias torch.Size([128]) 0.000512\n","transformer.layers.5.attn.linear.weight torch.Size([49, 1024]) 0.200704\n","transformer.layers.5.attn.linear.bias torch.Size([49]) 0.000196\n","transformer.layers.5.ffn.net.0.weight torch.Size([49]) 0.000196\n","transformer.layers.5.ffn.net.0.bias torch.Size([49]) 0.000196\n","transformer.layers.5.ffn.net.1.weight torch.Size([256, 49]) 0.050176\n","transformer.layers.5.ffn.net.1.bias torch.Size([256]) 0.001024\n","transformer.layers.5.ffn.net.3.weight torch.Size([49, 256]) 0.050176\n","transformer.layers.5.ffn.net.3.bias torch.Size([49]) 0.000196\n","norm.weight torch.Size([49]) 0.000196\n","norm.bias torch.Size([49]) 0.000196\n","summary_embed.net.0.weight torch.Size([290]) 0.00116\n","summary_embed.net.0.bias torch.Size([290]) 0.00116\n","summary_embed.net.1.weight torch.Size([256, 290]) 0.29696\n","summary_embed.net.1.bias torch.Size([256]) 0.001024\n","summary_embed.net.3.weight torch.Size([290, 256]) 0.29696\n","summary_embed.net.3.bias torch.Size([290]) 0.00116\n","head.weight torch.Size([310, 339]) 0.42036\n","head.bias torch.Size([310]) 0.00124\n"]}]},{"cell_type":"code","source":["len(train_ids), len(val_ids), len(test_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONLnQNlkzDr5","outputId":"74816135-0487-4f13-a28d-7bcc70e1d835"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(70, 67, 33)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"FDC_IPI3ICs8"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"ROs1QhWYIEAu","executionInfo":{"status":"ok","timestamp":1733877385080,"user_tz":300,"elapsed":149,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["print(f\"FINAL LOSSES: TRAIN {train_losses[-1]}, VAL {val_losses[-1]}, TEST {test_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Au2R14f38_PH","outputId":"cd5bcb23-f382-41c1-e91e-0ecdeafc0af9","executionInfo":{"status":"ok","timestamp":1733877386232,"user_tz":300,"elapsed":136,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["FINAL LOSSES: TRAIN 2.0403187722597287, VAL 2.0402101027116557, TEST 2.0403435948074504\n"]}]},{"cell_type":"code","source":["plt.plot(train_losses, label='train')\n","plt.plot(val_losses, label='val')\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss (averaged over all batches)')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"rszs4oy_9LMr","outputId":"4f430dd0-436d-458a-f34d-00612af6b943","executionInfo":{"status":"ok","timestamp":1733877388362,"user_tz":300,"elapsed":470,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":98,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def contains_nan(tensor):\n","    return torch.isnan(tensor).any()\n","\n","\n","def check_dataloader_for_nan(dataloader):\n","    for batch_idx, batch in enumerate(dataloader):\n","        if isinstance(batch, (tuple, list)):  # If batch is a tuple or list (e.g., data, label)\n","            for i, item in enumerate(batch):\n","                if isinstance(item, torch.Tensor) and contains_nan(item):\n","                    print(f\"NaN found in batch {batch_idx}, item {i}\")\n","                    return True\n","        elif isinstance(batch, torch.Tensor):  # If batch itself is a tensor\n","            if contains_nan(batch):\n","                print(f\"NaN found in batch {batch_idx}\")\n","                return True\n","    print(\"No NaNs found in the DataLoader.\")\n","    return False"],"metadata":{"id":"K5T1j-QWzRv7","executionInfo":{"status":"ok","timestamp":1733824548925,"user_tz":300,"elapsed":67,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["check_dataloader_for_nan(train_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmqgAl6I_p5w","executionInfo":{"status":"ok","timestamp":1733824833953,"user_tz":300,"elapsed":274569,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"a62bd4dd-229b-473f-fa6e-fa01ff14f4da"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["No NaNs found in the DataLoader.\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["check_dataloader_for_nan(val_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_DcArh0_zig","executionInfo":{"status":"ok","timestamp":1733824913459,"user_tz":300,"elapsed":79203,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"d63d39da-b164-4438-c2cb-f9114472657a"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["No NaNs found in the DataLoader.\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["check_dataloader_for_nan(test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"3gP2S3QJ_0uu","executionInfo":{"status":"error","timestamp":1733825244733,"user_tz":300,"elapsed":331282,"user":{"displayName":"Shepard Jiang","userId":"15346557307604532829"}},"outputId":"584a594c-b671-40da-8674-bccc47e9c805"},"execution_count":45,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-e33958050a22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_dataloader_for_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-b9ac976803bc>\u001b[0m in \u001b[0;36mcheck_dataloader_for_nan\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_dataloader_for_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If batch is a tuple or list (e.g., data, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"a8JU0AOw_1mH"},"execution_count":null,"outputs":[]}]}